apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: alertmanager
    creationTimestamp: "2025-04-16T11:40:24Z"
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app.kubernetes.io/component: alert-router
      app.kubernetes.io/instance: main
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 0.23.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: alertmanager-main-f67787f9b
      statefulset.kubernetes.io/pod-name: alertmanager-main-0
    name: alertmanager-main-0
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: dd53f019-52a1-4dfb-b919-5923acf95cb8
    resourceVersion: "70961512"
    uid: 69a9dff7-7b0c-4a0d-be2e-61c51f4ffeb4
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: alertmanager
                operator: In
                values:
                - main
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=[$(POD_IP)]:9094
      - --web.listen-address=:9093
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-1.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-2.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: prom/alertmanager:v0.23.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/healthy
          port: web
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      name: alertmanager
      ports:
      - containerPort: 9093
        name: web
        protocol: TCP
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: 200m
          memory: 200Mi
        requests:
          cpu: 20m
          memory: 30Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-main-db
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dgjc5
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:9093/-/reload
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dgjc5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-main-0
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-main-tls-assets-0
    - emptyDir: {}
      name: alertmanager-main-db
    - name: kube-api-access-dgjc5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:01Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:33:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:33:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://83d3a7274dc3c13f34fb2a8284fa61b6000722f22f1f06eb08e169b260035001
      image: docker.io/prom/alertmanager:v0.23.0
      imageID: docker.io/prom/alertmanager@sha256:9ab73a421b65b80be072f96a88df756fc5b52a1bc8d983537b8ec5be8b624c5a
      lastState:
        terminated:
          containerID: containerd://2605b34e67c17b384493f33e44b160dfc08138de11bdf3ad81ea156dd1d76c5d
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            .10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:25:48.502Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:03.503Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:18.501Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:33.501Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:48.503Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:27:03.502Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
          reason: Unknown
          startedAt: "2025-04-16T12:46:02Z"
      name: alertmanager
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:56Z"
    - containerID: containerd://5a6161c68a550eabccf5add303522a55ea42637f66a1db5f8ae3743d78fca320
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState:
        terminated:
          containerID: containerd://9964ab025e21788282695533afb1d9a00b91c2e3b7e98e5013079b941d65df10
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            level=info ts=2025-04-16T12:46:11.421804076Z caller=main.go:111 msg="Starting prometheus-config-reloader" version="(version=0.55.1, branch=refs/tags/v0.55.1, revision=08c846115c67195bc821018168040db6f3e236e3)"
            level=info ts=2025-04-16T12:46:11.536681435Z caller=main.go:112 build_context="(go=go1.17.7, user=Action-Run-ID-2045821452, date=20220326-21:47:32)"
            level=info ts=2025-04-16T12:46:11.667178872Z caller=reloader.go:235 msg="started watching config file and directories for changes" cfg= out= dirs=/etc/alertmanager/config
            level=info ts=2025-04-16T12:46:11.667178211Z caller=main.go:149 msg="Starting web server for metrics" listen=:8080
            level=info ts=2025-04-16T12:49:11.683275484Z caller=reloader.go:373 msg="Reload triggered" cfg_in= cfg_out= watched_dirs=/etc/alertmanager/config
          reason: Unknown
          startedAt: "2025-04-16T12:46:07Z"
      name: config-reloader
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:00Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.226
    podIPs:
    - ip: 192.168.3.226
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: alertmanager
    creationTimestamp: "2025-04-16T11:38:09Z"
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app.kubernetes.io/component: alert-router
      app.kubernetes.io/instance: main
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 0.23.0
      apps.kubernetes.io/pod-index: "1"
      controller-revision-hash: alertmanager-main-f67787f9b
      statefulset.kubernetes.io/pod-name: alertmanager-main-1
    name: alertmanager-main-1
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: dd53f019-52a1-4dfb-b919-5923acf95cb8
    resourceVersion: "70961437"
    uid: ffb39224-d2f8-4be0-b2bd-859563f83d86
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: alertmanager
                operator: In
                values:
                - main
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=[$(POD_IP)]:9094
      - --web.listen-address=:9093
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-1.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-2.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: prom/alertmanager:v0.23.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/healthy
          port: web
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      name: alertmanager
      ports:
      - containerPort: 9093
        name: web
        protocol: TCP
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: 200m
          memory: 200Mi
        requests:
          cpu: 20m
          memory: 30Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-main-db
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pfj45
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:9093/-/reload
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pfj45
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-main-1
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-main-tls-assets-0
    - emptyDir: {}
      name: alertmanager-main-db
    - name: kube-api-access-pfj45
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:33:02Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:33:02Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7824c5e01e3fc90edaf650e6c6fd8e7b91f917730722566c788f592f8d34ae7f
      image: docker.io/prom/alertmanager:v0.23.0
      imageID: docker.io/prom/alertmanager@sha256:9ab73a421b65b80be072f96a88df756fc5b52a1bc8d983537b8ec5be8b624c5a
      lastState:
        terminated:
          containerID: containerd://279df295c11e799ced75af2bbd890dadf03474e0fabe2bf69ba2481c9b9a470c
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            .10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:25:48.499Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:03.500Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:18.501Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:33.500Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:48.500Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:27:03.501Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
          reason: Unknown
          startedAt: "2025-04-16T12:46:02Z"
      name: alertmanager
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:40Z"
    - containerID: containerd://ee15b53c902721bb740d683768fe0b1022d99339c314b03a5235378e3e4631ff
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState:
        terminated:
          containerID: containerd://02350b85887b390c80ba8cdabcf3154bc967f1bfbd53aaabab571818e36d7283
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            level=info ts=2025-04-16T12:46:11.421810419Z caller=main.go:111 msg="Starting prometheus-config-reloader" version="(version=0.55.1, branch=refs/tags/v0.55.1, revision=08c846115c67195bc821018168040db6f3e236e3)"
            level=info ts=2025-04-16T12:46:11.536629445Z caller=main.go:112 build_context="(go=go1.17.7, user=Action-Run-ID-2045821452, date=20220326-21:47:32)"
            level=info ts=2025-04-16T12:46:11.667161679Z caller=reloader.go:235 msg="started watching config file and directories for changes" cfg= out= dirs=/etc/alertmanager/config
            level=info ts=2025-04-16T12:46:11.667148474Z caller=main.go:149 msg="Starting web server for metrics" listen=:8080
            level=info ts=2025-04-16T12:49:11.673229453Z caller=reloader.go:373 msg="Reload triggered" cfg_in= cfg_out= watched_dirs=/etc/alertmanager/config
          reason: Unknown
          startedAt: "2025-04-16T12:46:07Z"
      name: config-reloader
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:41Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.218
    podIPs:
    - ip: 192.168.3.218
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: alertmanager
    creationTimestamp: "2025-04-16T11:38:11Z"
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app.kubernetes.io/component: alert-router
      app.kubernetes.io/instance: main
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 0.23.0
      apps.kubernetes.io/pod-index: "2"
      controller-revision-hash: alertmanager-main-f67787f9b
      statefulset.kubernetes.io/pod-name: alertmanager-main-2
    name: alertmanager-main-2
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: dd53f019-52a1-4dfb-b919-5923acf95cb8
    resourceVersion: "72238386"
    uid: feb7679e-c0b5-4589-a2e0-655776177f04
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: alertmanager
                operator: In
                values:
                - main
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=[$(POD_IP)]:9094
      - --web.listen-address=:9093
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-1.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-2.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: prom/alertmanager:v0.23.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/healthy
          port: web
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      name: alertmanager
      ports:
      - containerPort: 9093
        name: web
        protocol: TCP
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: 200m
          memory: 200Mi
        requests:
          cpu: 20m
          memory: 30Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-main-db
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-x8sgj
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:9093/-/reload
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-x8sgj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-main-2
    nodeName: zee8608workerapi01
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-main-tls-assets-0
    - emptyDir: {}
      name: alertmanager-main-db
    - name: kube-api-access-x8sgj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:34:21Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:34:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:34:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://8e197e35b6ed434c83380bfa05f11a0d430851bfb2362a8d295e2b6e65b6ddaa
      image: docker.io/prom/alertmanager:v0.23.0
      imageID: docker.io/prom/alertmanager@sha256:9ab73a421b65b80be072f96a88df756fc5b52a1bc8d983537b8ec5be8b624c5a
      lastState: {}
      name: alertmanager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:34:11Z"
    - containerID: containerd://b04be828e45c3aa5fedd0b25ab0246217d8a87df6bcd6b3c7de244760a8c529d
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:34:19Z"
    hostIP: 10.48.219.138
    hostIPs:
    - ip: 10.48.219.138
    phase: Running
    podIP: 192.168.5.204
    podIPs:
    - ip: 192.168.5.204
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:40:17Z"
    generateName: kube-state-metrics-99bf7fbb6-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 2.6.0
      pod-template-hash: 99bf7fbb6
    name: kube-state-metrics-99bf7fbb6-ntzsh
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-state-metrics-99bf7fbb6
      uid: 2586c0b1-7d7b-48e7-a791-40da15dfd71c
    resourceVersion: "70961409"
    uid: f3f763f4-39d4-4cb9-8a8b-533fd2a0c306
  spec:
    affinity: {}
    containers:
    - args:
      - --host=127.0.0.1
      - --port=8081
      - --telemetry-host=127.0.0.1
      - --telemetry-port=8082
      - --metric-denylist=kube_.+_version,kube_.+_created,kube_deployment_(spec_paused|spec_strategy_rollingupdate_.+),kube_endpoint_(info|address_.+),kube_job_(info|owner|spec_(parallelism|active_deadline_seconds)|status_(active|.+_time)),kube_cronjob_(info|status_.+|spec_.+),kube_namespace_(status_phase),kube_persistentvolume_(info|capacity_.+),kube_persistentvolumeclaim_(resource_.+|access_.+),kube_secret_(type),kube_service_(spec_.+|status_.+),kube_ingress_(info|path|tls),kube_replicaset_(status_.+|spec_.+|owner),kube_poddisruptionbudget_status_.+,kube_replicationcontroller_.+,kube_node_info,kube_(hpa|replicaset|replicationcontroller)_.+_generation
      - --metric-labels-allowlist=namespaces=[kubesphere.io/workspace],storageclasses=[storage.kubesphere.io/storagetype]
      image: kubesphere/kube-state-metrics:v2.6.0
      imagePullPolicy: IfNotPresent
      name: kube-state-metrics
      resources:
        limits:
          cpu: "1"
          memory: 8Gi
        requests:
          cpu: 100m
          memory: 150Mi
      securityContext:
        runAsUser: 65534
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/localtime
        name: host-time
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4567t
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:8443
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:8081/
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-main
      ports:
      - containerPort: 8443
        name: https-main
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4567t
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9443
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:8082/
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-self
      ports:
      - containerPort: 9443
        name: https-self
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4567t
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-state-metrics
    serviceAccountName: kube-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /etc/localtime
        type: ""
      name: host-time
    - name: kube-api-access-4567t
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://546b4442742e8f19a8cb1c37e6d353882c9dba02fc44abbb950537a7caef510d
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://bd43e6e6de5440d2e3fa7319669e7dd730fdc72d124573af41bdbd3ed2c9a718
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:50:17Z"
      name: kube-rbac-proxy-main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:40Z"
    - containerID: containerd://ccd09c58391f6ce59f614f329d459198854de1e8ef59dc05bbf2ec9ad898f7f9
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://7e1cb76a6c1e7af69e947a17b501bdbab2c30ca4374b969374de8c726889d4b7
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:50:17Z"
      name: kube-rbac-proxy-self
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:41Z"
    - containerID: containerd://41d677bae85eada71a6348e645385866e420595130efcc2f8c6fa440be094185
      image: docker.io/kubesphere/kube-state-metrics:v2.6.0
      imageID: docker.io/kubesphere/kube-state-metrics@sha256:bdab4e49d71d272cf944c8612dff5ab1250f0fafdae45c22980286ac0c016032
      lastState:
        terminated:
          containerID: containerd://6a3016989558b0c8e27169c7a21c8e5be11d16121fe1316e14a1d092e4bb59b5
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:50:17Z"
      name: kube-state-metrics
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:40Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.217
    podIPs:
    - ip: 192.168.3.217
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-10T07:02:11Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 7f57ff6bf5
      pod-template-generation: "1"
    name: node-exporter-2n9vd
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 57c8536a-cdea-4fe5-840d-c6f0289d5d7b
    resourceVersion: "70961637"
    uid: f762f5dd-4952-477d-b56f-fd0a7a296e43
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi03
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --no-collector.hwmon
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      image: prom/node-exporter:v1.3.1
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 102m
          memory: 180Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vk2kg
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9100/
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vk2kg
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: zee8608workerapi03
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: kube-api-access-vk2kg
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:34:38Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:34:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:34:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://1bda79a7cf781b267eef45dda175ed70d0f743df0b0a4adc148fa5a118ee1822
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://f1e5a03ac4ef17efcdcc7fd486b68bda0dba12174b7741877572b7d13687a676
          exitCode: 255
          finishedAt: "2025-06-20T20:34:22Z"
          reason: Unknown
          startedAt: "2025-04-16T12:43:49Z"
      name: kube-rbac-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:34:38Z"
    - containerID: containerd://3e837d75d7f799fe0518fc265bf67c397f28d0b6b490cf6915ad5744b52b200a
      image: docker.io/prom/node-exporter:v1.3.1
      imageID: docker.io/prom/node-exporter@sha256:f2269e73124dd0f60a7d19a2ce1264d33d08a985aed0ee6b0b89d0be470592cd
      lastState:
        terminated:
          containerID: containerd://14edd0b41015f7e553792b7901ecd8a4da9991bcb8e6662c7ad5bf3b512242c6
          exitCode: 255
          finishedAt: "2025-06-20T20:34:22Z"
          reason: Unknown
          startedAt: "2025-04-16T12:43:48Z"
      name: node-exporter
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:34:37Z"
    hostIP: 10.48.219.140
    hostIPs:
    - ip: 10.48.219.140
    phase: Running
    podIP: 10.48.219.140
    podIPs:
    - ip: 10.48.219.140
    qosClass: Burstable
    startTime: "2025-02-10T07:02:11Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-10T07:02:11Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 7f57ff6bf5
      pod-template-generation: "1"
    name: node-exporter-8c59f
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 57c8536a-cdea-4fe5-840d-c6f0289d5d7b
    resourceVersion: "70961466"
    uid: 4bb0547b-4ec5-4925-addd-56866feacd41
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi02
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --no-collector.hwmon
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      image: prom/node-exporter:v1.3.1
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 102m
          memory: 180Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jnkhc
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9100/
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jnkhc
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: kube-api-access-jnkhc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:48Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:12Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9efb6713afab7175248274da311434d48e67e7d1675900070f1e5eb12649749c
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://f3ee98b06423f79fb6885344eb04bb317e3b9de8a77de541320acf9b638a8903
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:20:18Z"
      name: kube-rbac-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:30:48Z"
    - containerID: containerd://9dbc60bf9b503fa8a3b2a1eaee1c5a1ab61a567fa32129b83f9766ac084bf4af
      image: docker.io/prom/node-exporter:v1.3.1
      imageID: docker.io/prom/node-exporter@sha256:f2269e73124dd0f60a7d19a2ce1264d33d08a985aed0ee6b0b89d0be470592cd
      lastState:
        terminated:
          containerID: containerd://618c6fff5147ca3fe9d76fbeb0678d84f20d75aef8370bd4bad2762f255db171
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:20:18Z"
      name: node-exporter
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:30:46Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 10.48.219.139
    podIPs:
    - ip: 10.48.219.139
    qosClass: Burstable
    startTime: "2025-02-10T07:02:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-10T07:02:11Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 7f57ff6bf5
      pod-template-generation: "1"
    name: node-exporter-9gthb
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 57c8536a-cdea-4fe5-840d-c6f0289d5d7b
    resourceVersion: "70961728"
    uid: 51552759-cc7f-4e69-add3-70ae5c359f1d
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608masterapi01
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --no-collector.hwmon
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      image: prom/node-exporter:v1.3.1
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 102m
          memory: 180Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-88w8c
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9100/
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-88w8c
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: zee8608masterapi01
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: kube-api-access-88w8c
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:20:20Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:20:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:20:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://2b17b08956162c4a31280a9458c26976d8fc3cf4bf9fcbc79fa4a6505c07d968
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://f65b62496470191262a5fe61cd77856b20f099dd87b574671d900c16c8c728ad
          exitCode: 255
          finishedAt: "2025-06-20T20:20:11Z"
          reason: Unknown
          startedAt: "2025-06-20T20:17:04Z"
      name: kube-rbac-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:20:20Z"
    - containerID: containerd://bc1dab9905053216bbb774f5fe6ab89f830f3d20ea6d316deef016b08a6b01f8
      image: docker.io/prom/node-exporter:v1.3.1
      imageID: docker.io/prom/node-exporter@sha256:f2269e73124dd0f60a7d19a2ce1264d33d08a985aed0ee6b0b89d0be470592cd
      lastState:
        terminated:
          containerID: containerd://a17b3e0f6b64ed192ea355d261d058a0c3a995ddf1f47d810520b6094abc5917
          exitCode: 255
          finishedAt: "2025-06-20T20:20:11Z"
          reason: Unknown
          startedAt: "2025-06-20T20:17:02Z"
      name: node-exporter
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:20:19Z"
    hostIP: 10.48.219.135
    hostIPs:
    - ip: 10.48.219.135
    phase: Running
    podIP: 10.48.219.135
    podIPs:
    - ip: 10.48.219.135
    qosClass: Burstable
    startTime: "2025-02-10T07:02:11Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-10T07:02:11Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 7f57ff6bf5
      pod-template-generation: "1"
    name: node-exporter-b9qql
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 57c8536a-cdea-4fe5-840d-c6f0289d5d7b
    resourceVersion: "70961315"
    uid: 4828d02c-182a-4078-b915-32e1f6168091
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608masterapi02
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --no-collector.hwmon
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      image: prom/node-exporter:v1.3.1
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 102m
          memory: 180Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5vw8x
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9100/
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5vw8x
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: zee8608masterapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: kube-api-access-5vw8x
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:14:48Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:14:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:14:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://00156c837d0843ea621bae7afebe0b97dd8f1efddb9658fed3980be737a82d40
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://4fcea2e4ee0994376ca7e8655383f31bfbbae3d0ac94e652fbd637a9ea926799
          exitCode: 255
          finishedAt: "2025-06-20T20:14:36Z"
          reason: Unknown
          startedAt: "2025-06-20T20:12:21Z"
      name: kube-rbac-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:14:46Z"
    - containerID: containerd://d0a0a7c96ec82a9062c0e5c6c740fa242af215b486cc50dd0e701ed08e9e5876
      image: docker.io/prom/node-exporter:v1.3.1
      imageID: docker.io/prom/node-exporter@sha256:f2269e73124dd0f60a7d19a2ce1264d33d08a985aed0ee6b0b89d0be470592cd
      lastState:
        terminated:
          containerID: containerd://b07d5f3d2a3073d8f51068536d0595bb25cef470b4fb10093b0c826d4dcd50fb
          exitCode: 255
          finishedAt: "2025-06-20T20:14:36Z"
          reason: Unknown
          startedAt: "2025-06-20T20:12:16Z"
      name: node-exporter
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:14:44Z"
    hostIP: 10.48.219.136
    hostIPs:
    - ip: 10.48.219.136
    phase: Running
    podIP: 10.48.219.136
    podIPs:
    - ip: 10.48.219.136
    qosClass: Burstable
    startTime: "2025-02-10T07:02:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-10T07:02:11Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 7f57ff6bf5
      pod-template-generation: "1"
    name: node-exporter-vks64
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 57c8536a-cdea-4fe5-840d-c6f0289d5d7b
    resourceVersion: "70967204"
    uid: b03f74b7-8c0b-4f3e-b83e-549d5194817b
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi01
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --no-collector.hwmon
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      image: prom/node-exporter:v1.3.1
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 102m
          memory: 180Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-n7wmd
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9100/
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-n7wmd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: zee8608workerapi01
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: kube-api-access-n7wmd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:28:51Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:12Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:28:51Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:28:51Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://829b3a331f245d96d010640693e8272eede02e1da346ccdec6a7aa5906426d8e
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:28:51Z"
    - containerID: containerd://f418c7d4c316147d21c387804c34d4f9f45b2a718e4afae319d84e4b419e77fb
      image: docker.io/prom/node-exporter:v1.3.1
      imageID: docker.io/prom/node-exporter@sha256:f2269e73124dd0f60a7d19a2ce1264d33d08a985aed0ee6b0b89d0be470592cd
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:28:47Z"
    hostIP: 10.48.219.138
    hostIPs:
    - ip: 10.48.219.138
    phase: Running
    podIP: 10.48.219.138
    podIPs:
    - ip: 10.48.219.138
    qosClass: Burstable
    startTime: "2025-02-10T07:02:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-10T07:02:11Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 7f57ff6bf5
      pod-template-generation: "1"
    name: node-exporter-x78rx
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 57c8536a-cdea-4fe5-840d-c6f0289d5d7b
    resourceVersion: "70961307"
    uid: f805c1a6-bfeb-4546-9c5d-b8f9c0772579
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608masterapi03
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --no-collector.hwmon
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      image: prom/node-exporter:v1.3.1
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 102m
          memory: 180Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-gsrxn
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9100/
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-gsrxn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: zee8608masterapi03
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: kube-api-access-gsrxn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:24:16Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:24:16Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:24:16Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9923b966cc9ddc7f3dacd3b73317efe38d8b512ea68de5ce1886a998fd1faa58
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://58be96ba6461c2ed4a2271b2b764602b0bcf94232267712179ad8cf4a9604630
          exitCode: 255
          finishedAt: "2025-06-20T20:24:06Z"
          reason: Unknown
          startedAt: "2025-06-20T20:20:17Z"
      name: kube-rbac-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:24:15Z"
    - containerID: containerd://56fff4b635de95e398359c79437a278b76abd497053657c26f7a645e192c2b17
      image: docker.io/prom/node-exporter:v1.3.1
      imageID: docker.io/prom/node-exporter@sha256:f2269e73124dd0f60a7d19a2ce1264d33d08a985aed0ee6b0b89d0be470592cd
      lastState:
        terminated:
          containerID: containerd://273a3993e1494ed2d443a201f0e7b67a4f38a4c879616cb0c1509c9499a13359
          exitCode: 255
          finishedAt: "2025-06-20T20:24:06Z"
          reason: Unknown
          startedAt: "2025-06-20T20:20:16Z"
      name: node-exporter
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:24:12Z"
    hostIP: 10.48.219.137
    hostIPs:
    - ip: 10.48.219.137
    phase: Running
    podIP: 10.48.219.137
    podIPs:
    - ip: 10.48.219.137
    qosClass: Burstable
    startTime: "2025-02-10T07:02:10Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:38:04Z"
    generateName: notification-manager-deployment-c9d789f99-
    labels:
      app: notification-manager
      notification-manager: notification-manager
      pod-template-hash: c9d789f99
    name: notification-manager-deployment-c9d789f99-4pw4l
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: notification-manager-deployment-c9d789f99
      uid: fceec78a-ae96-4af7-bfb1-a1732e1ad323
    resourceVersion: "72238179"
    uid: 58ddbff9-54ec-4186-a067-a4812ae5f62e
  spec:
    affinity: {}
    containers:
    - env:
      - name: NAMESPACE
        value: kubesphere-monitoring-federated
      image: kubesphere/notification-manager:v2.3.0
      imagePullPolicy: IfNotPresent
      name: notification-manager
      ports:
      - containerPort: 19093
        name: webhook
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 500Mi
        requests:
          cpu: 5m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-p8cht
        readOnly: true
    - image: kubesphere/notification-tenant-sidecar:v3.2.0
      imagePullPolicy: IfNotPresent
      name: tenant
      ports:
      - containerPort: 19094
        name: tenant
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-p8cht
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi01
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: notification-manager-sa
    serviceAccountName: notification-manager-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-p8cht
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:33:53Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:33:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:33:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9aea600e99c50b93f81ba8dc8aa03aba806b8c7b55aaeb612d26481458ed227e
      image: docker.io/kubesphere/notification-manager:v2.3.0
      imageID: docker.io/kubesphere/notification-manager@sha256:8a208b905cfc4620832d9e4807e6390cfa27b8ec5e8d0ebd0f1a781503b7fc34
      lastState: {}
      name: notification-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:33:52Z"
    - containerID: containerd://d5850ceff4827c1fc686da24877853a98068b116ed76e8b537cd13a8b0dee070
      image: docker.io/kubesphere/notification-tenant-sidecar:v3.2.0
      imageID: docker.io/kubesphere/notification-tenant-sidecar@sha256:32c98dac712c0b08bd1e16dc3fb5a2241d5a0f8580f8f92b2a53c83d0cae2578
      lastState: {}
      name: tenant
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:33:53Z"
    hostIP: 10.48.219.138
    hostIPs:
    - ip: 10.48.219.138
    phase: Running
    podIP: 192.168.5.201
    podIPs:
    - ip: 192.168.5.201
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:40:17Z"
    generateName: notification-manager-deployment-c9d789f99-
    labels:
      app: notification-manager
      notification-manager: notification-manager
      pod-template-hash: c9d789f99
    name: notification-manager-deployment-c9d789f99-785kq
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: notification-manager-deployment-c9d789f99
      uid: fceec78a-ae96-4af7-bfb1-a1732e1ad323
    resourceVersion: "70971663"
    uid: dff6d041-b68f-49d1-b17b-4c5324ca28a5
  spec:
    affinity: {}
    containers:
    - env:
      - name: NAMESPACE
        value: kubesphere-monitoring-federated
      image: kubesphere/notification-manager:v2.3.0
      imagePullPolicy: IfNotPresent
      name: notification-manager
      ports:
      - containerPort: 19093
        name: webhook
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 500Mi
        requests:
          cpu: 5m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-99jcd
        readOnly: true
    - image: kubesphere/notification-tenant-sidecar:v3.2.0
      imagePullPolicy: IfNotPresent
      name: tenant
      ports:
      - containerPort: 19094
        name: tenant
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-99jcd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: notification-manager-sa
    serviceAccountName: notification-manager-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-99jcd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:02Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:09:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:09:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7dfae675832714888f4eab7548ce8286cc994012d51c67dfbbd79994034d24b9
      image: docker.io/kubesphere/notification-manager:v2.3.0
      imageID: docker.io/kubesphere/notification-manager@sha256:8a208b905cfc4620832d9e4807e6390cfa27b8ec5e8d0ebd0f1a781503b7fc34
      lastState:
        terminated:
          containerID: containerd://2cce364318f235c02fd93cf70f2ef7d6e6b3dcfce7305f1fd27832caa3c9859d
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:46:05Z"
      name: notification-manager
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:55Z"
    - containerID: containerd://5075509da1b1d112d4f9b041a3338f455ea0e00fcc63edc8a6616def3deec9a1
      image: docker.io/kubesphere/notification-tenant-sidecar:v3.2.0
      imageID: docker.io/kubesphere/notification-tenant-sidecar@sha256:32c98dac712c0b08bd1e16dc3fb5a2241d5a0f8580f8f92b2a53c83d0cae2578
      lastState:
        terminated:
          containerID: containerd://99a7226b6b73edcc06d6a8964744d2138141fb8c6bdec92b4e4008b90b13e4ec
          exitCode: 1
          finishedAt: "2025-06-20T21:04:16Z"
          reason: Error
          startedAt: "2025-06-20T21:04:16Z"
      name: tenant
      ready: true
      restartCount: 16
      started: true
      state:
        running:
          startedAt: "2025-06-20T21:09:26Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.224
    podIPs:
    - ip: 192.168.3.224
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:40:17Z"
    generateName: notification-manager-operator-9949f4878-
    labels:
      control-plane: controller-manager
      pod-template-hash: 9949f4878
    name: notification-manager-operator-9949f4878-x9vqw
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: notification-manager-operator-9949f4878
      uid: 4764bed3-304c-4992-b336-dcea8b5c0305
    resourceVersion: "70961442"
    uid: 5686fda7-525b-4379-86f0-e0cd41e0125d
  spec:
    affinity: {}
    containers:
    - args:
      - --secure-listen-address=0.0.0.0:8443
      - --upstream=http://127.0.0.1:8080/
      - --logtostderr=true
      - --v=10
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 50m
          memory: 50Mi
        requests:
          cpu: 5m
          memory: 10Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9rrfp
        readOnly: true
    - args:
      - --metrics-addr=127.0.0.1:8080
      - --enable-leader-election
      command:
      - /notification-manager-operator
      env:
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: kubesphere/notification-manager-operator:v2.3.0
      imagePullPolicy: IfNotPresent
      name: notification-manager-operator
      ports:
      - containerPort: 9443
        name: webhook-server
        protocol: TCP
      resources:
        limits:
          cpu: 50m
          memory: 50Mi
        requests:
          cpu: 5m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/k8s-webhook-server/serving-certs
        name: cert
        readOnly: true
      - mountPath: /etc/localtime
        name: host-time
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9rrfp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: notification-manager-sa
    serviceAccountName: notification-manager-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: cert
      secret:
        defaultMode: 420
        secretName: notification-manager-webhook-server-cert
    - hostPath:
        path: /etc/localtime
        type: ""
      name: host-time
    - name: kube-api-access-9rrfp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5966853002ef97ae2509ae5c056eafb9241a5152cb2fd1eea8f5c74d989b453a
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:40Z"
    - containerID: containerd://94b71db3d870e85df357c0e20d438057f514a83148adb54b3a68b58d98eb43c1
      image: docker.io/kubesphere/notification-manager-operator:v2.3.0
      imageID: docker.io/kubesphere/notification-manager-operator@sha256:a7c3671f5c15d1f24f822f01de997d4bff78700e52290f94da8be80927e09a94
      lastState:
        terminated:
          containerID: containerd://db133e4333d1660e4564736fa56fa1cfa71713cc42207e363732fcb68df08a21
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-06-20T20:21:12Z"
      name: notification-manager-operator
      ready: true
      restartCount: 6
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:41Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.219
    podIPs:
    - ip: 192.168.3.219
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: prometheus
    creationTimestamp: "2025-06-23T16:34:56Z"
    generateName: prometheus-k8s-
    labels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 2.39.1
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: prometheus-k8s-745fccb79c
      operator.prometheus.io/name: k8s
      operator.prometheus.io/shard: "0"
      prometheus: k8s
      statefulset.kubernetes.io/pod-name: prometheus-k8s-0
    name: prometheus-k8s-0
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-k8s
      uid: 5d38d7dc-8f61-4eb2-81b7-07cb7d961443
    resourceVersion: "72241136"
    uid: 601d7697-6e24-4ba3-a10d-79083ee01871
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/monitoring
              operator: Exists
          weight: 100
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: prometheus
                app.kubernetes.io/instance: k8s
                app.kubernetes.io/name: prometheus
                app.kubernetes.io/part-of: kube-prometheus
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --storage.tsdb.retention.time=7d
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
      - --query.max-concurrency=1000
      - --web.route-prefix=/
      - --web.config.file=/etc/prometheus/web_config/web-config.yaml
      image: prom/prometheus:v2.39.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /-/healthy
          port: web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      name: prometheus
      ports:
      - containerPort: 9090
        name: web
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: "4"
          memory: 16Gi
        requests:
          cpu: 200m
          memory: 400Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/prometheus/certs
        name: tls-assets
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-k8s-db
        subPath: prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /etc/prometheus/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7h9dt
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7h9dt
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-k8s-0
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8080
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7h9dt
        readOnly: true
    nodeName: zee8608workerapi01
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 0
      runAsNonRoot: false
      runAsUser: 0
    serviceAccount: prometheus-k8s
    serviceAccountName: prometheus-k8s
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoSchedule
      key: dedicated
      operator: Equal
      value: monitoring
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: prometheus-k8s-db
      persistentVolumeClaim:
        claimName: prometheus-k8s-db-prometheus-k8s-0
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: prometheus-k8s-tls-assets-0
    - emptyDir: {}
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-k8s-rulefiles-0
      name: prometheus-k8s-rulefiles-0
    - name: web-config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-web-config
    - name: kube-api-access-7h9dt
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:39:29Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:39:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:39:44Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:39:44Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:39:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://39f7e4c80604d7e616b2a73decf52b418347dae475abce4d88539e53bffbb1a2
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:39:29Z"
    - containerID: containerd://3b21f1cdfe813f84ae6fbd449eb3b1e73234208ab9caa7fa5f213ff5f44e0d8e
      image: docker.io/prom/prometheus:v2.39.1
      imageID: docker.io/prom/prometheus@sha256:4748e26f9369ee7270a7cd3fb9385c1adb441c05792ce2bce2f6dd622fd91d38
      lastState: {}
      name: prometheus
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:39:29Z"
    hostIP: 10.48.219.138
    hostIPs:
    - ip: 10.48.219.138
    initContainerStatuses:
    - containerID: containerd://8ef7da54769e9f1cfc394d8c56acfb58260cf559116836950d005eb5a8fdd24b
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://8ef7da54769e9f1cfc394d8c56acfb58260cf559116836950d005eb5a8fdd24b
          exitCode: 0
          finishedAt: "2025-06-23T16:39:29Z"
          reason: Completed
          startedAt: "2025-06-23T16:39:29Z"
    phase: Running
    podIP: 192.168.5.228
    podIPs:
    - ip: 192.168.5.228
    qosClass: Burstable
    startTime: "2025-06-23T16:39:19Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: prometheus
    creationTimestamp: "2025-06-20T20:42:57Z"
    generateName: prometheus-k8s-
    labels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 2.39.1
      apps.kubernetes.io/pod-index: "1"
      controller-revision-hash: prometheus-k8s-745fccb79c
      operator.prometheus.io/name: k8s
      operator.prometheus.io/shard: "0"
      prometheus: k8s
      statefulset.kubernetes.io/pod-name: prometheus-k8s-1
    name: prometheus-k8s-1
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-k8s
      uid: 5d38d7dc-8f61-4eb2-81b7-07cb7d961443
    resourceVersion: "70961763"
    uid: b96580f1-5e2d-4d9b-b984-ee7ed9d830c6
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/monitoring
              operator: Exists
          weight: 100
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: prometheus
                app.kubernetes.io/instance: k8s
                app.kubernetes.io/name: prometheus
                app.kubernetes.io/part-of: kube-prometheus
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --storage.tsdb.retention.time=7d
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
      - --query.max-concurrency=1000
      - --web.route-prefix=/
      - --web.config.file=/etc/prometheus/web_config/web-config.yaml
      image: prom/prometheus:v2.39.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /-/healthy
          port: web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      name: prometheus
      ports:
      - containerPort: 9090
        name: web
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: "4"
          memory: 16Gi
        requests:
          cpu: 200m
          memory: 400Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/prometheus/certs
        name: tls-assets
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-k8s-db
        subPath: prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /etc/prometheus/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-m8zc5
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-m8zc5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-k8s-1
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8080
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-m8zc5
        readOnly: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 0
      runAsNonRoot: false
      runAsUser: 0
    serviceAccount: prometheus-k8s
    serviceAccountName: prometheus-k8s
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoSchedule
      key: dedicated
      operator: Equal
      value: monitoring
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: prometheus-k8s-db
      persistentVolumeClaim:
        claimName: prometheus-k8s-db-prometheus-k8s-1
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: prometheus-k8s-tls-assets-0
    - emptyDir: {}
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-k8s-rulefiles-0
      name: prometheus-k8s-rulefiles-0
    - name: web-config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-web-config
    - name: kube-api-access-m8zc5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:23Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:37Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:37Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:42:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://163663182cffc9b41e38986e81dbe9f4aa23e577863e9b0d85ccc42bbc2213e4
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:43:23Z"
    - containerID: containerd://63de1855f7296a205d3950d190d8426768b7e3a8e54e404ae2b72a21ec8d1c93
      image: docker.io/prom/prometheus:v2.39.1
      imageID: docker.io/prom/prometheus@sha256:4748e26f9369ee7270a7cd3fb9385c1adb441c05792ce2bce2f6dd622fd91d38
      lastState: {}
      name: prometheus
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:43:23Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    initContainerStatuses:
    - containerID: containerd://cce7e488d543d9e3ffd38fc90a5010efe6f47082c20fcedfc692ebd762dc2900
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://cce7e488d543d9e3ffd38fc90a5010efe6f47082c20fcedfc692ebd762dc2900
          exitCode: 0
          finishedAt: "2025-06-20T20:43:22Z"
          reason: Completed
          startedAt: "2025-06-20T20:43:22Z"
    phase: Running
    podIP: 192.168.3.242
    podIPs:
    - ip: 192.168.3.242
    qosClass: Burstable
    startTime: "2025-06-20T20:43:17Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: prometheus-operator
    creationTimestamp: "2025-04-16T11:38:05Z"
    generateName: prometheus-operator-7888d46fbd-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/name: prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: v0.55.1
      pod-template-hash: 7888d46fbd
    name: prometheus-operator-7888d46fbd-bxbr2
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-operator-7888d46fbd
      uid: 7c2ce707-9dc5-4ef8-b683-d23a233162b6
    resourceVersion: "72238471"
    uid: 164c6c58-96cf-4308-8012-c5ef3456d63f
  spec:
    affinity: {}
    containers:
    - args:
      - --kubelet-service=kube-system/kubelet
      - --prometheus-config-reloader=kubesphere/prometheus-config-reloader:v0.55.1
      image: kubesphere/prometheus-operator:v0.55.1
      imagePullPolicy: IfNotPresent
      name: prometheus-operator
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      resources:
        limits:
          cpu: 200m
          memory: 200Mi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rdwrb
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:8443
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:8080/
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rdwrb
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi01
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: prometheus-operator
    serviceAccountName: prometheus-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-rdwrb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:34:31Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:34:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:34:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://d5f9766121e75c99f762f3138ba02bd23ec96e3a2dd9a508bfcf174c70e5f95a
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:34:30Z"
    - containerID: containerd://6d3909f76089b084796895e5bf59717820e49642b2fe4d4fdf80db136632300c
      image: docker.io/kubesphere/prometheus-operator:v0.55.1
      imageID: docker.io/kubesphere/prometheus-operator@sha256:4eed7c8a413cdbf865b155591e63322212db44d8b932037a8d08eb7e1964e569
      lastState: {}
      name: prometheus-operator
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:34:16Z"
    hostIP: 10.48.219.138
    hostIPs:
    - ip: 10.48.219.138
    phase: Running
    podIP: 192.168.5.210
    podIPs:
    - ip: 192.168.5.210
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: thanos-ruler
    creationTimestamp: "2025-04-16T11:40:24Z"
    generateName: thanos-ruler-kubesphere-
    labels:
      app.kubernetes.io/component: thanos-ruler
      app.kubernetes.io/instance: kubesphere
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: thanos-ruler
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 0.31.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: thanos-ruler-kubesphere-7d97bc46ff
      statefulset.kubernetes.io/pod-name: thanos-ruler-kubesphere-0
      thanos-ruler: kubesphere
    name: thanos-ruler-kubesphere-0
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: thanos-ruler-kubesphere
      uid: 7515b72f-709c-4a9c-822d-fcdbc676e0dc
    resourceVersion: "70963305"
    uid: ff212f55-b536-4c2e-9b19-0e6d66e396d7
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: thanos-ruler
                app.kubernetes.io/instance: kubesphere
                app.kubernetes.io/name: thanos-ruler
                app.kubernetes.io/part-of: kube-prometheus
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - rule
      - --data-dir=/thanos/data
      - --eval-interval=1m
      - --tsdb.retention=24h
      - --label=thanos_ruler_replica="$(POD_NAME)"
      - --alert.label-drop=thanos_ruler_replica
      - --query=http://prometheus-operated.kubesphere-monitoring-system.svc:9090
      - --rule-file=/etc/thanos/rules/*/*.yaml
      - --alertmanagers.url=dnssrv+http://alertmanager-operated.kubesphere-monitoring-system.svc:9093
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      image: thanosio/thanos:v0.31.0
      imagePullPolicy: IfNotPresent
      name: thanos-ruler
      ports:
      - containerPort: 10901
        name: grpc
        protocol: TCP
      - containerPort: 10902
        name: web
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /thanos/data
        name: thanos-ruler-kubesphere-data
      - mountPath: /etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
        name: thanos-ruler-kubesphere-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lrpkk
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:10902/-/reload
      - --watched-dir=/etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
        name: thanos-ruler-kubesphere-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lrpkk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: thanos-ruler-kubesphere-0
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: thanos-ruler-kubesphere-rulefiles-0
      name: thanos-ruler-kubesphere-rulefiles-0
    - emptyDir: {}
      name: thanos-ruler-kubesphere-data
    - name: kube-api-access-lrpkk
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:04Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:48:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:48:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e954843c2ef93c16af01894d649168fc2181f1a40b3a687cbf0aee75ef1e5b02
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState:
        terminated:
          containerID: containerd://96db9ea893e371b7eb861853f58eccfbc7f0c0a7da9579d0d336f81a3a03fe91
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            level=info ts=2025-04-16T12:48:35.24843867Z caller=main.go:111 msg="Starting prometheus-config-reloader" version="(version=0.55.1, branch=refs/tags/v0.55.1, revision=08c846115c67195bc821018168040db6f3e236e3)"
            level=info ts=2025-04-16T12:48:35.248503274Z caller=main.go:112 build_context="(go=go1.17.7, user=Action-Run-ID-2045821452, date=20220326-21:47:32)"
            level=info ts=2025-04-16T12:48:35.248760017Z caller=main.go:149 msg="Starting web server for metrics" listen=:8080
            level=info ts=2025-04-16T12:48:35.24887646Z caller=reloader.go:235 msg="started watching config file and directories for changes" cfg= out= dirs=/etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
            level=info ts=2025-04-16T12:51:35.441256588Z caller=reloader.go:373 msg="Reload triggered" cfg_in= cfg_out= watched_dirs=/etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
            level=info ts=2025-04-25T07:53:07.3180103Z caller=reloader.go:373 msg="Reload triggered" cfg_in= cfg_out= watched_dirs=/etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
          reason: Unknown
          startedAt: "2025-04-16T12:48:35Z"
      name: config-reloader
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:04Z"
    - containerID: containerd://b8b21ae2e573dabaa108f28ccbac1374505d0d4ca27aff645216ecbc95682b56
      image: docker.io/thanosio/thanos:v0.31.0
      imageID: docker.io/thanosio/thanos@sha256:e7d337d6ac2aea3f0f9314ec9830291789e16e2b480b9d353be02d05ce7f2a7e
      lastState:
        terminated:
          containerID: containerd://32f8b6e54b04c4f9993254b3d7739385992a2df1b9fbd3998756e2960ee885f5
          exitCode: 1
          finishedAt: "2025-06-20T20:42:58Z"
          message: |
            ller=http.go:110 component=rules service=http/server component=rule msg="internal server is shutdown gracefully" err="lookup SRV records \"alertmanager-operated.kubesphere-monitoring-system.svc\": could not resolve \"alertmanager-operated.kubesphere-monitoring-system.svc\": all servers responded with errors to at least one search domain. Errs ;could not resolve alertmanager-operated.kubesphere-monitoring-system.svc.: no servers returned a viable answer. Errs ;resolution against server 10.96.0.10 for alertmanager-operated.kubesphere-monitoring-system.svc.: exchange: read udp 192.168.3.227:47648->10.96.0.10:53: i/o timeout"
            level=info ts=2025-06-20T20:42:58.143203597Z caller=intrumentation.go:81 component=rules msg="changing probe status" status=not-healthy reason="lookup SRV records \"alertmanager-operated.kubesphere-monitoring-system.svc\": could not resolve \"alertmanager-operated.kubesphere-monitoring-system.svc\": all servers responded with errors to at least one search domain. Errs ;could not resolve alertmanager-operated.kubesphere-monitoring-system.svc.: no servers returned a viable answer. Errs ;resolution against server 10.96.0.10 for alertmanager-operated.kubesphere-monitoring-system.svc.: exchange: read udp 192.168.3.227:47648->10.96.0.10:53: i/o timeout"
            level=error ts=2025-06-20T20:42:58.143264201Z caller=main.go:161 err="lookup SRV records \"alertmanager-operated.kubesphere-monitoring-system.svc\": could not resolve \"alertmanager-operated.kubesphere-monitoring-system.svc\": all servers responded with errors to at least one search domain. Errs ;could not resolve alertmanager-operated.kubesphere-monitoring-system.svc.: no servers returned a viable answer. Errs ;resolution against server 10.96.0.10 for alertmanager-operated.kubesphere-monitoring-system.svc.: exchange: read udp 192.168.3.227:47648->10.96.0.10:53: i/o timeout\nrule command failed\nmain.main\n\t/app/cmd/thanos/main.go:161\nruntime.main\n\t/usr/local/go/src/runtime/proc.go:250\nruntime.goexit\n\t/usr/local/go/src/runtime/asm_amd64.s:1594"
          reason: Error
          startedAt: "2025-06-20T20:38:26Z"
      name: thanos-ruler
      ready: true
      restartCount: 26
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:48:08Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.227
    podIPs:
    - ip: 192.168.3.227
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: thanos-ruler
    creationTimestamp: "2025-04-16T11:24:54Z"
    generateName: thanos-ruler-kubesphere-
    labels:
      app.kubernetes.io/component: thanos-ruler
      app.kubernetes.io/instance: kubesphere
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: thanos-ruler
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 0.31.0
      apps.kubernetes.io/pod-index: "1"
      controller-revision-hash: thanos-ruler-kubesphere-7d97bc46ff
      statefulset.kubernetes.io/pod-name: thanos-ruler-kubesphere-1
      thanos-ruler: kubesphere
    name: thanos-ruler-kubesphere-1
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: thanos-ruler-kubesphere
      uid: 7515b72f-709c-4a9c-822d-fcdbc676e0dc
    resourceVersion: "72238137"
    uid: 387dd8a9-c3a4-440f-bbc3-6ec7170ea500
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: thanos-ruler
                app.kubernetes.io/instance: kubesphere
                app.kubernetes.io/name: thanos-ruler
                app.kubernetes.io/part-of: kube-prometheus
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - rule
      - --data-dir=/thanos/data
      - --eval-interval=1m
      - --tsdb.retention=24h
      - --label=thanos_ruler_replica="$(POD_NAME)"
      - --alert.label-drop=thanos_ruler_replica
      - --query=http://prometheus-operated.kubesphere-monitoring-system.svc:9090
      - --rule-file=/etc/thanos/rules/*/*.yaml
      - --alertmanagers.url=dnssrv+http://alertmanager-operated.kubesphere-monitoring-system.svc:9093
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      image: thanosio/thanos:v0.31.0
      imagePullPolicy: IfNotPresent
      name: thanos-ruler
      ports:
      - containerPort: 10901
        name: grpc
        protocol: TCP
      - containerPort: 10902
        name: web
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /thanos/data
        name: thanos-ruler-kubesphere-data
      - mountPath: /etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
        name: thanos-ruler-kubesphere-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ggpnn
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:10902/-/reload
      - --watched-dir=/etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
        name: thanos-ruler-kubesphere-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ggpnn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: thanos-ruler-kubesphere-1
    nodeName: zee8608workerapi01
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: thanos-ruler-kubesphere-rulefiles-0
      name: thanos-ruler-kubesphere-rulefiles-0
    - emptyDir: {}
      name: thanos-ruler-kubesphere-data
    - name: kube-api-access-ggpnn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:33:50Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:33:50Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:33:50Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9eb356e3dc5c89c6623217013923aaf704e27774ba105ecda5a470be23213805
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:33:49Z"
    - containerID: containerd://fcf0224b6de4c52f7c69358bae5bc8bf19f3b2ad904ab277aef08aa7a0144b9d
      image: docker.io/thanosio/thanos:v0.31.0
      imageID: docker.io/thanosio/thanos@sha256:e7d337d6ac2aea3f0f9314ec9830291789e16e2b480b9d353be02d05ce7f2a7e
      lastState: {}
      name: thanos-ruler
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:33:49Z"
    hostIP: 10.48.219.138
    hostIPs:
    - ip: 10.48.219.138
    phase: Running
    podIP: 192.168.5.196
    podIPs:
    - ip: 192.168.5.196
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
kind: List
metadata:
  resourceVersion: ""
