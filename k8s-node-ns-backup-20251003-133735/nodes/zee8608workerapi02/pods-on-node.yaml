apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/path: /metrics
      prometheus.io/port: "9402"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-04-16T11:40:16Z"
    generateName: cert-manager-97f647775-
    labels:
      app: cert-manager
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/name: cert-manager
      app.kubernetes.io/version: v1.17.0
      pod-template-hash: 97f647775
    name: cert-manager-97f647775-wxbkc
    namespace: cert-manager
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cert-manager-97f647775
      uid: c98f2745-34bc-49af-881a-656a370331b7
    resourceVersion: "70961505"
    uid: e40e7bd4-7282-4935-ade6-7815c1c275ea
  spec:
    containers:
    - args:
      - --v=2
      - --cluster-resource-namespace=$(POD_NAMESPACE)
      - --leader-election-namespace=kube-system
      - --acme-http01-solver-image=quay.io/jetstack/cert-manager-acmesolver:v1.17.0
      - --max-concurrent-challenges=60
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: quay.io/jetstack/cert-manager-controller:v1.17.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          path: /livez
          port: http-healthz
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: cert-manager-controller
      ports:
      - containerPort: 9402
        name: http-metrics
        protocol: TCP
      - containerPort: 9403
        name: http-healthz
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zzncs
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: false
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: cert-manager
    serviceAccountName: cert-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-zzncs
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://db8bf82b42806db59070375c8d34af781d40f6e8c66f50c84eb61fdecabeadd4
      image: quay.io/jetstack/cert-manager-controller:v1.17.0
      imageID: quay.io/jetstack/cert-manager-controller@sha256:424263d7a11b54b56b26953d22bf28bd87338056b518dd007e391ad0b702c5f0
      lastState:
        terminated:
          containerID: containerd://e39a87b0e8990b197edf466daf39d17394e1583f98ed95efcced923b93eb5693
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-06-20T20:20:08Z"
      name: cert-manager-controller
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:05Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.234
    podIPs:
    - ip: 192.168.3.234
    qosClass: BestEffort
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-06-12T22:34:11+05:30"
    creationTimestamp: "2025-06-12T17:09:57Z"
    generateName: ingress-nginx-controller-57fb89d679-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.12.0
      helm.sh/chart: ingress-nginx-4.12.0
      pod-template-hash: 57fb89d679
    name: ingress-nginx-controller-57fb89d679-t8hfl
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ingress-nginx-controller-57fb89d679
      uid: cdaae733-cafc-4791-882c-80e360740bde
    resourceVersion: "70961519"
    uid: b4c0a828-32db-4e96-99cc-9dc5e076ec84
  spec:
    containers:
    - args:
      - /nginx-ingress-controller
      - --publish-service=$(POD_NAMESPACE)/ingress-nginx-controller
      - --election-id=ingress-nginx-leader
      - --controller-class=k8s.io/ingress-nginx
      - --ingress-class=nginx
      - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
      - --validating-webhook=:8443
      - --validating-webhook-certificate=/usr/local/certificates/cert
      - --validating-webhook-key=/usr/local/certificates/key
      - --tcp-services-configmap=ingress-nginx/redis-tcp-services
      - --tcp-services-configmap=ingress-nginx/mongo-tcp-services
      - --enable-ssl-passthrough
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: LD_PRELOAD
        value: /usr/local/lib/libmimalloc.so
      image: registry.k8s.io/ingress-nginx/controller:v1.12.0@sha256:e6b8de175acda6ca913891f0f727bca4527e797d52688cbe9fec9040d6f6b6fa
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /wait-shutdown
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 80
        name: http
        protocol: TCP
      - containerPort: 443
        name: https
        protocol: TCP
      - containerPort: 8443
        name: webhook
        protocol: TCP
      - containerPort: 6379
        hostPort: 6379
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 90Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: false
        runAsGroup: 82
        runAsNonRoot: true
        runAsUser: 101
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/local/certificates/
        name: webhook-cert
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-v7xvj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: ingress-nginx
    serviceAccountName: ingress-nginx
    terminationGracePeriodSeconds: 300
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: webhook-cert
      secret:
        defaultMode: 420
        secretName: ingress-nginx-admission
    - name: kube-api-access-v7xvj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:47Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-12T17:11:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:00Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:00Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-12T17:10:40Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://aaa23f73f86197f4367c107ad33e4e8f38b55874169aea8d60c8c37a5274b43e
      image: sha256:a4a8af0db08902e65347157c5efef6d1f9e261f03c8aa14b1b40bc182b947fe7
      imageID: registry.k8s.io/ingress-nginx/controller@sha256:e6b8de175acda6ca913891f0f727bca4527e797d52688cbe9fec9040d6f6b6fa
      lastState:
        terminated:
          containerID: containerd://4567807591b4339e1fe44ba915981dc65865c83b75fcc537454e412daa2eec76
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-06-12T17:11:25Z"
      name: controller
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:46Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.223
    podIPs:
    - ip: 192.168.3.223
    qosClass: Burstable
    startTime: "2025-06-12T17:11:24Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-07T08:28:35Z"
    generateName: kube-flannel-ds-
    labels:
      app: flannel
      controller-revision-hash: 6d455c8676
      pod-template-generation: "1"
      tier: node
    name: kube-flannel-ds-h9rrs
    namespace: kube-flannel
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-flannel-ds
      uid: f5ae3f66-75e9-4802-8abb-8c580d4ab38a
    resourceVersion: "70961403"
    uid: dc7506e0-41fc-4fe5-9cab-7f98eea41157
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi02
    containers:
    - args:
      - --ip-masq
      - --kube-subnet-mgr
      command:
      - /opt/bin/flanneld
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: EVENT_QUEUE_DEPTH
        value: "5000"
      image: ghcr.io/flannel-io/flannel:v0.26.4
      imagePullPolicy: IfNotPresent
      name: kube-flannel
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/flannel
        name: run
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bq7bh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - args:
      - -f
      - /flannel
      - /opt/cni/bin/flannel
      command:
      - cp
      image: ghcr.io/flannel-io/flannel-cni-plugin:v1.6.2-flannel1
      imagePullPolicy: IfNotPresent
      name: install-cni-plugin
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-plugin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bq7bh
        readOnly: true
    - args:
      - -f
      - /etc/kube-flannel/cni-conf.json
      - /etc/cni/net.d/10-flannel.conflist
      command:
      - cp
      image: ghcr.io/flannel-io/flannel:v0.26.4
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bq7bh
        readOnly: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: flannel
    serviceAccountName: flannel
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /run/flannel
        type: ""
      name: run
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-plugin
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni
    - configMap:
        defaultMode: 420
        name: kube-flannel-cfg
      name: flannel-cfg
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - name: kube-api-access-bq7bh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:46Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T08:28:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T08:28:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f028bbdbc98a7fab43839cb1e9cc8d77b2ea697e67ce870fc063bd81a41ece70
      image: ghcr.io/flannel-io/flannel:v0.26.4
      imageID: ghcr.io/flannel-io/flannel@sha256:b4dcecb6192041d99f57999d70e101c22536c2b058b99f6d00497ca99c470f53
      lastState:
        terminated:
          containerID: containerd://e30705e8f8dcd44bf9b41835e44caa4d3862a2c86474d94a541ccb5177c3dfba
          exitCode: 1
          finishedAt: "2025-06-20T20:31:23Z"
          reason: Error
          startedAt: "2025-06-20T20:30:51Z"
      name: kube-flannel
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:38Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    initContainerStatuses:
    - containerID: containerd://b2f650b4f2633ad6550f61de10df2e546636fe5eb5b0f3336062499c5ee760b8
      image: ghcr.io/flannel-io/flannel-cni-plugin:v1.6.2-flannel1
      imageID: ghcr.io/flannel-io/flannel-cni-plugin@sha256:f1812994f0edbcb5bb5ccb63be2147ba6ad10e1faaa7ca9fcdad4f441739d84f
      lastState: {}
      name: install-cni-plugin
      ready: true
      restartCount: 2
      started: false
      state:
        terminated:
          containerID: containerd://b2f650b4f2633ad6550f61de10df2e546636fe5eb5b0f3336062499c5ee760b8
          exitCode: 0
          finishedAt: "2025-06-20T20:30:47Z"
          reason: Completed
          startedAt: "2025-06-20T20:30:46Z"
    - containerID: containerd://e2251067bab8ecf8312febb25f99ef476d6bbb2fcbdf16c3bd355264b862b735
      image: ghcr.io/flannel-io/flannel:v0.26.4
      imageID: ghcr.io/flannel-io/flannel@sha256:b4dcecb6192041d99f57999d70e101c22536c2b058b99f6d00497ca99c470f53
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://e2251067bab8ecf8312febb25f99ef476d6bbb2fcbdf16c3bd355264b862b735
          exitCode: 0
          finishedAt: "2025-06-20T20:30:50Z"
          reason: Completed
          startedAt: "2025-06-20T20:30:49Z"
    phase: Running
    podIP: 10.48.219.139
    podIPs:
    - ip: 10.48.219.139
    qosClass: Burstable
    startTime: "2025-02-07T08:28:35Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-07T08:04:39Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 79c94c5cb4
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-7hm8t
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: 27c3a05f-34c7-4b31-afaa-6a1d52f7b481
    resourceVersion: "70961404"
    uid: e7f68172-2ae9-423c-b640-0213b3d72fa6
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi02
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.30.9
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-q54c8
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-q54c8
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:45Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T08:04:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T08:04:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://0a4c555e4ec55a3f176a6313d53f8519da56e816498c2917e71e8663e48b99fd
      image: registry.k8s.io/kube-proxy:v1.30.9
      imageID: registry.k8s.io/kube-proxy@sha256:d78dc40d97ff862fd8ddb47f80a5ba3feec17bc73e58a60e963885e33faa0083
      lastState:
        terminated:
          containerID: containerd://a8ec3ed65b205310ce9cc2ab35cdd7c0358169f12b6b222f382f1eaf4cbd2475
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:20:17Z"
      name: kube-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:30:45Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 10.48.219.139
    podIPs:
    - ip: 10.48.219.139
    qosClass: BestEffort
    startTime: "2025-02-07T08:04:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-06-20T21:05:36Z"
    generateName: metrics-server-b79d5c976-
    labels:
      k8s-app: metrics-server
      pod-template-hash: b79d5c976
    name: metrics-server-b79d5c976-27hfl
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metrics-server-b79d5c976
      uid: f1ce1c1a-1ec9-4559-bdd4-4ba9f43ccd64
    resourceVersion: "70971602"
    uid: 4497d0b1-e43e-4b47-8ae3-21825ea74827
  spec:
    containers:
    - args:
      - --cert-dir=/tmp
      - --secure-port=10250
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --kubelet-use-node-status-port
      - --metric-resolution=15s
      - --kubelet-insecure-tls
      image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: metrics-server
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: https
          scheme: HTTPS
        initialDelaySeconds: 20
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-w58ln
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metrics-server
    serviceAccountName: metrics-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp-dir
    - name: kube-api-access-w58ln
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:06:09Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:05:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:09:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:09:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:05:36Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f6fe87445377fa30a3e8b8384cc6efbc43d69851e0bb98e5acc185ca2771002a
      image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
      imageID: registry.k8s.io/metrics-server/metrics-server@sha256:ffcb2bf004d6aa0a17d90e0247cf94f2865c8901dcab4427034c341951c239f9
      lastState: {}
      name: metrics-server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T21:08:56Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.8
    podIPs:
    - ip: 192.168.3.8
    qosClass: Burstable
    startTime: "2025-06-20T21:05:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:40:21Z"
    generateName: snapshot-controller-
    labels:
      app: snapshot-controller
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: snapshot-controller-7d87fc7c78
      statefulset.kubernetes.io/pod-name: snapshot-controller-0
    name: snapshot-controller-0
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: snapshot-controller
      uid: a5bcb0f8-f08b-455e-a8b6-857b22fa5155
    resourceVersion: "70961417"
    uid: 56290ebb-0d2a-4e73-a56f-70d3f066bc05
  spec:
    containers:
    - args:
      - --v=5
      - --leader-election=false
      image: csiplugin/snapshot-controller:v4.0.0
      imagePullPolicy: IfNotPresent
      name: snapshot-controller
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-2zcst
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: snapshot-controller-0
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: snapshot-controller
    serviceAccountName: snapshot-controller
    subdomain: snapshot-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-2zcst
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:05Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:05Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:05Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://62577e50e2a8038f21167ff5f90343ef2cb3d704bf919d0e929b4115cbbfe38a
      image: docker.io/csiplugin/snapshot-controller:v4.0.0
      imageID: docker.io/csiplugin/snapshot-controller@sha256:00fcc441ea9f72899c25eed61d602272a2a58c5f0014332bdcb5ac24acef08e4
      lastState:
        terminated:
          containerID: containerd://67567a806cc6f999dd61e0b2d1d3a999829c2fa6170daee4f78ca7b9dc16bb69
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:49:51Z"
      name: snapshot-controller
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:03Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.230
    podIPs:
    - ip: 192.168.3.230
    qosClass: BestEffort
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:40:16Z"
    generateName: kubectl-admin-6bb69fcfdf-
    labels:
      kubesphere.io/username: admin
      pod-template-hash: 6bb69fcfdf
    name: kubectl-admin-6bb69fcfdf-zfndf
    namespace: kubesphere-controls-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kubectl-admin-6bb69fcfdf
      uid: b03e6fb2-e5f4-4bad-9b3b-b73f7bf7ebc8
    resourceVersion: "70961486"
    uid: 8f62a4d7-52e2-48e8-a177-ec5c944f9e36
  spec:
    containers:
    - image: kubesphere/kubectl:v1.22.0
      imagePullPolicy: IfNotPresent
      name: kubectl
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/localtime
        name: host-time
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bnzq6
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubesphere-cluster-admin
    serviceAccountName: kubesphere-cluster-admin
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /etc/localtime
        type: ""
      name: host-time
    - name: kube-api-access-bnzq6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:02Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:02Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:02Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://fa25d3c20b9125b98aa999ac37b1b1827bef69554529630f9289f5512c5a1e21
      image: docker.io/kubesphere/kubectl:v1.22.0
      imageID: docker.io/kubesphere/kubectl@sha256:32c554d9eaaf6c509d00244243f24b2cb32b8aa5ebb59ac44562629c372a16b8
      lastState:
        terminated:
          containerID: containerd://592b44de555b838bc02ca1245f561e5694bde823e498738db855f0f1306c0313
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:48:58Z"
      name: kubectl
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:01Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.228
    podIPs:
    - ip: 192.168.3.228
    qosClass: BestEffort
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-06-23T16:45:30Z"
    generateName: fluent-bit-
    labels:
      app.kubernetes.io/name: fluent-bit
      controller-revision-hash: 767db976
      pod-template-generation: "1"
    name: fluent-bit-jzkzz
    namespace: kubesphere-logging-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: fluent-bit
      uid: 2576eaf5-f050-486e-aa27-04a9d8690e49
    resourceVersion: "72244749"
    uid: 224087e0-ff23-4e5f-9a09-ff11ba607ab5
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi02
    containers:
    - env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: kubesphere/fluent-bit:v1.9.4
      imagePullPolicy: IfNotPresent
      name: fluent-bit
      ports:
      - containerPort: 2020
        name: metrics
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 200Mi
        requests:
          cpu: 10m
          memory: 25Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/log/containers
        name: varlibcontainers
        readOnly: true
      - mountPath: /fluent-bit/config
        name: config
        readOnly: true
      - mountPath: /var/log/
        name: varlogs
        readOnly: true
      - mountPath: /var/log/journal
        name: systemd
        readOnly: true
      - mountPath: /fluent-bit/tail
        name: positions
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7np5z
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: fluent-bit
    serviceAccountName: fluent-bit
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/log/containers
        type: ""
      name: varlibcontainers
    - name: config
      secret:
        defaultMode: 420
        secretName: fluent-bit-config
    - hostPath:
        path: /var/log
        type: ""
      name: varlogs
    - hostPath:
        path: /var/log/journal
        type: ""
      name: systemd
    - emptyDir: {}
      name: positions
    - name: kube-api-access-7np5z
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:45:31Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:45:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:45:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:45:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:45:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://b3c8bb3a1a631714e857208727dfeed8f88f5c5b45eb7a29ee61603e05568843
      image: docker.io/kubesphere/fluent-bit:v1.9.4
      imageID: docker.io/kubesphere/fluent-bit@sha256:c14d673ad2c51b5441075f8811ec3d899a3abfce3950fe26ea0e51628199af65
      lastState: {}
      name: fluent-bit
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:45:30Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.16
    podIPs:
    - ip: 192.168.3.16
    qosClass: Burstable
    startTime: "2025-06-23T16:45:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      configchecksum: eb70eea659188d444ae38c6d48b6cce2f1c6bd3d9a4b073c07f3839a50e6a01
      kubectl.kubernetes.io/restartedAt: "2025-04-25T13:01:23+05:30"
    creationTimestamp: "2025-06-23T16:45:30Z"
    generateName: opensearch-cluster-master-
    labels:
      app.kubernetes.io/component: opensearch-cluster-master
      app.kubernetes.io/instance: opensearch-master
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: opensearch
      app.kubernetes.io/version: 2.6.0
      apps.kubernetes.io/pod-index: "1"
      controller-revision-hash: opensearch-cluster-master-856cd98799
      helm.sh/chart: opensearch-2.11.0
      statefulset.kubernetes.io/pod-name: opensearch-cluster-master-1
    name: opensearch-cluster-master-1
    namespace: kubesphere-logging-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: opensearch-cluster-master
      uid: 02876eb4-d790-4e1f-b787-812b274eddf5
    resourceVersion: "72247640"
    uid: b21a01af-69e9-4bb5-b7a1-f0503a96a48a
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/instance
                operator: In
                values:
                - opensearch-master
              - key: app.kubernetes.io/name
                operator: In
                values:
                - opensearch
            topologyKey: kubernetes.io/hostname
          weight: 1
    containers:
    - env:
      - name: node.name
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: cluster.initial_master_nodes
        value: opensearch-cluster-master-0,opensearch-cluster-master-1,opensearch-cluster-master-2,
      - name: discovery.seed_hosts
        value: opensearch-cluster-master-headless
      - name: cluster.name
        value: opensearch-cluster
      - name: network.host
        value: 0.0.0.0
      - name: OPENSEARCH_JAVA_OPTS
        value: -Xmx512M -Xms512M
      - name: node.roles
        value: master,
      image: opensearchproject/opensearch:2.6.0
      imagePullPolicy: IfNotPresent
      name: opensearch
      ports:
      - containerPort: 9200
        name: http
        protocol: TCP
      - containerPort: 9300
        name: transport
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        periodSeconds: 5
        successThreshold: 1
        tcpSocket:
          port: 9200
        timeoutSeconds: 3
      resources:
        requests:
          cpu: "1"
          memory: 512Mi
      securityContext:
        capabilities:
          drop:
          - ALL
        runAsNonRoot: true
        runAsUser: 1000
      startupProbe:
        failureThreshold: 30
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: 9200
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/share/opensearch/data
        name: opensearch-cluster-master
      - mountPath: /usr/share/opensearch/config/opensearch.yml
        name: config
        subPath: opensearch.yml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bnxlw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: opensearch-cluster-master-1
    initContainers:
    - args:
      - chown -R 1000:1000 /usr/share/opensearch/data
      command:
      - sh
      - -c
      image: busybox:latest
      imagePullPolicy: Always
      name: fsgroup-volume
      resources: {}
      securityContext:
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/share/opensearch/data
        name: opensearch-cluster-master
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bnxlw
        readOnly: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000
      runAsUser: 1000
    serviceAccount: default
    serviceAccountName: default
    subdomain: opensearch-cluster-master-headless
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: opensearch-cluster-master
      persistentVolumeClaim:
        claimName: opensearch-cluster-master-opensearch-cluster-master-1
    - configMap:
        defaultMode: 420
        name: opensearch-cluster-master-config
      name: config
    - name: kube-api-access-bnxlw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:46:27Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:46:27Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:50:24Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:50:24Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-23T16:45:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://6e13fc81c943a1b95ab11ff2ea5486c4f6728a20b5fc6698a5e7622e6fefc0bf
      image: docker.io/opensearchproject/opensearch:2.6.0
      imageID: docker.io/opensearchproject/opensearch@sha256:40f5bb40a543f7ea6458bc0ecffc7679c9df6f8836a9e3781a78829d587ef552
      lastState:
        terminated:
          containerID: containerd://3936296052ce24289838f302f7b1c94b2a271ddef349052986c03e79585a12e0
          exitCode: 78
          finishedAt: "2025-06-23T16:48:41Z"
          reason: Error
          startedAt: "2025-06-23T16:48:32Z"
      name: opensearch
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2025-06-23T16:50:06Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    initContainerStatuses:
    - containerID: containerd://0203e255c4e774b6fc489509b2ca1fb2435b34e9b4eba275b01888e0bf769382
      image: docker.io/library/busybox:latest
      imageID: docker.io/library/busybox@sha256:f85340bf132ae937d2c2a763b8335c9bab35d6e8293f70f606b9c6178d84f42b
      lastState: {}
      name: fsgroup-volume
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://0203e255c4e774b6fc489509b2ca1fb2435b34e9b4eba275b01888e0bf769382
          exitCode: 0
          finishedAt: "2025-06-23T16:46:26Z"
          reason: Completed
          startedAt: "2025-06-23T16:46:26Z"
    phase: Running
    podIP: 192.168.3.17
    podIPs:
    - ip: 192.168.3.17
    qosClass: Burstable
    startTime: "2025-06-23T16:45:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: alertmanager
    creationTimestamp: "2025-04-16T11:40:24Z"
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app.kubernetes.io/component: alert-router
      app.kubernetes.io/instance: main
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 0.23.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: alertmanager-main-f67787f9b
      statefulset.kubernetes.io/pod-name: alertmanager-main-0
    name: alertmanager-main-0
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: dd53f019-52a1-4dfb-b919-5923acf95cb8
    resourceVersion: "70961512"
    uid: 69a9dff7-7b0c-4a0d-be2e-61c51f4ffeb4
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: alertmanager
                operator: In
                values:
                - main
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=[$(POD_IP)]:9094
      - --web.listen-address=:9093
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-1.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-2.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: prom/alertmanager:v0.23.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/healthy
          port: web
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      name: alertmanager
      ports:
      - containerPort: 9093
        name: web
        protocol: TCP
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: 200m
          memory: 200Mi
        requests:
          cpu: 20m
          memory: 30Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-main-db
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dgjc5
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:9093/-/reload
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dgjc5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-main-0
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-main-tls-assets-0
    - emptyDir: {}
      name: alertmanager-main-db
    - name: kube-api-access-dgjc5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:01Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:33:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:33:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://83d3a7274dc3c13f34fb2a8284fa61b6000722f22f1f06eb08e169b260035001
      image: docker.io/prom/alertmanager:v0.23.0
      imageID: docker.io/prom/alertmanager@sha256:9ab73a421b65b80be072f96a88df756fc5b52a1bc8d983537b8ec5be8b624c5a
      lastState:
        terminated:
          containerID: containerd://2605b34e67c17b384493f33e44b160dfc08138de11bdf3ad81ea156dd1d76c5d
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            .10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:25:48.502Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:03.503Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:18.501Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:33.501Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:48.503Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:27:03.502Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
          reason: Unknown
          startedAt: "2025-04-16T12:46:02Z"
      name: alertmanager
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:56Z"
    - containerID: containerd://5a6161c68a550eabccf5add303522a55ea42637f66a1db5f8ae3743d78fca320
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState:
        terminated:
          containerID: containerd://9964ab025e21788282695533afb1d9a00b91c2e3b7e98e5013079b941d65df10
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            level=info ts=2025-04-16T12:46:11.421804076Z caller=main.go:111 msg="Starting prometheus-config-reloader" version="(version=0.55.1, branch=refs/tags/v0.55.1, revision=08c846115c67195bc821018168040db6f3e236e3)"
            level=info ts=2025-04-16T12:46:11.536681435Z caller=main.go:112 build_context="(go=go1.17.7, user=Action-Run-ID-2045821452, date=20220326-21:47:32)"
            level=info ts=2025-04-16T12:46:11.667178872Z caller=reloader.go:235 msg="started watching config file and directories for changes" cfg= out= dirs=/etc/alertmanager/config
            level=info ts=2025-04-16T12:46:11.667178211Z caller=main.go:149 msg="Starting web server for metrics" listen=:8080
            level=info ts=2025-04-16T12:49:11.683275484Z caller=reloader.go:373 msg="Reload triggered" cfg_in= cfg_out= watched_dirs=/etc/alertmanager/config
          reason: Unknown
          startedAt: "2025-04-16T12:46:07Z"
      name: config-reloader
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:00Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.226
    podIPs:
    - ip: 192.168.3.226
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: alertmanager
    creationTimestamp: "2025-04-16T11:38:09Z"
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app.kubernetes.io/component: alert-router
      app.kubernetes.io/instance: main
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 0.23.0
      apps.kubernetes.io/pod-index: "1"
      controller-revision-hash: alertmanager-main-f67787f9b
      statefulset.kubernetes.io/pod-name: alertmanager-main-1
    name: alertmanager-main-1
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: dd53f019-52a1-4dfb-b919-5923acf95cb8
    resourceVersion: "70961437"
    uid: ffb39224-d2f8-4be0-b2bd-859563f83d86
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: alertmanager
                operator: In
                values:
                - main
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=[$(POD_IP)]:9094
      - --web.listen-address=:9093
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-1.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-2.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: prom/alertmanager:v0.23.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/healthy
          port: web
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      name: alertmanager
      ports:
      - containerPort: 9093
        name: web
        protocol: TCP
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: 200m
          memory: 200Mi
        requests:
          cpu: 20m
          memory: 30Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-main-db
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pfj45
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:9093/-/reload
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pfj45
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-main-1
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-main-tls-assets-0
    - emptyDir: {}
      name: alertmanager-main-db
    - name: kube-api-access-pfj45
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:33:02Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:33:02Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7824c5e01e3fc90edaf650e6c6fd8e7b91f917730722566c788f592f8d34ae7f
      image: docker.io/prom/alertmanager:v0.23.0
      imageID: docker.io/prom/alertmanager@sha256:9ab73a421b65b80be072f96a88df756fc5b52a1bc8d983537b8ec5be8b624c5a
      lastState:
        terminated:
          containerID: containerd://279df295c11e799ced75af2bbd890dadf03474e0fabe2bf69ba2481c9b9a470c
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            .10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:25:48.499Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:03.500Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:18.501Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:33.500Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:26:48.500Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
            level=warn ts=2025-06-20T20:27:03.501Z caller=cluster.go:461 component=cluster msg=refresh result=failure addr=alertmanager-main-2.alertmanager-operated:9094 err="1 error occurred:\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated:9094: lookup alertmanager-main-2.alertmanager-operated on 10.96.0.10:53: no such host\n\n"
          reason: Unknown
          startedAt: "2025-04-16T12:46:02Z"
      name: alertmanager
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:40Z"
    - containerID: containerd://ee15b53c902721bb740d683768fe0b1022d99339c314b03a5235378e3e4631ff
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState:
        terminated:
          containerID: containerd://02350b85887b390c80ba8cdabcf3154bc967f1bfbd53aaabab571818e36d7283
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            level=info ts=2025-04-16T12:46:11.421810419Z caller=main.go:111 msg="Starting prometheus-config-reloader" version="(version=0.55.1, branch=refs/tags/v0.55.1, revision=08c846115c67195bc821018168040db6f3e236e3)"
            level=info ts=2025-04-16T12:46:11.536629445Z caller=main.go:112 build_context="(go=go1.17.7, user=Action-Run-ID-2045821452, date=20220326-21:47:32)"
            level=info ts=2025-04-16T12:46:11.667161679Z caller=reloader.go:235 msg="started watching config file and directories for changes" cfg= out= dirs=/etc/alertmanager/config
            level=info ts=2025-04-16T12:46:11.667148474Z caller=main.go:149 msg="Starting web server for metrics" listen=:8080
            level=info ts=2025-04-16T12:49:11.673229453Z caller=reloader.go:373 msg="Reload triggered" cfg_in= cfg_out= watched_dirs=/etc/alertmanager/config
          reason: Unknown
          startedAt: "2025-04-16T12:46:07Z"
      name: config-reloader
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:41Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.218
    podIPs:
    - ip: 192.168.3.218
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:40:17Z"
    generateName: kube-state-metrics-99bf7fbb6-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 2.6.0
      pod-template-hash: 99bf7fbb6
    name: kube-state-metrics-99bf7fbb6-ntzsh
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-state-metrics-99bf7fbb6
      uid: 2586c0b1-7d7b-48e7-a791-40da15dfd71c
    resourceVersion: "70961409"
    uid: f3f763f4-39d4-4cb9-8a8b-533fd2a0c306
  spec:
    affinity: {}
    containers:
    - args:
      - --host=127.0.0.1
      - --port=8081
      - --telemetry-host=127.0.0.1
      - --telemetry-port=8082
      - --metric-denylist=kube_.+_version,kube_.+_created,kube_deployment_(spec_paused|spec_strategy_rollingupdate_.+),kube_endpoint_(info|address_.+),kube_job_(info|owner|spec_(parallelism|active_deadline_seconds)|status_(active|.+_time)),kube_cronjob_(info|status_.+|spec_.+),kube_namespace_(status_phase),kube_persistentvolume_(info|capacity_.+),kube_persistentvolumeclaim_(resource_.+|access_.+),kube_secret_(type),kube_service_(spec_.+|status_.+),kube_ingress_(info|path|tls),kube_replicaset_(status_.+|spec_.+|owner),kube_poddisruptionbudget_status_.+,kube_replicationcontroller_.+,kube_node_info,kube_(hpa|replicaset|replicationcontroller)_.+_generation
      - --metric-labels-allowlist=namespaces=[kubesphere.io/workspace],storageclasses=[storage.kubesphere.io/storagetype]
      image: kubesphere/kube-state-metrics:v2.6.0
      imagePullPolicy: IfNotPresent
      name: kube-state-metrics
      resources:
        limits:
          cpu: "1"
          memory: 8Gi
        requests:
          cpu: 100m
          memory: 150Mi
      securityContext:
        runAsUser: 65534
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/localtime
        name: host-time
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4567t
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:8443
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:8081/
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-main
      ports:
      - containerPort: 8443
        name: https-main
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4567t
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9443
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:8082/
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-self
      ports:
      - containerPort: 9443
        name: https-self
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4567t
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-state-metrics
    serviceAccountName: kube-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /etc/localtime
        type: ""
      name: host-time
    - name: kube-api-access-4567t
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://546b4442742e8f19a8cb1c37e6d353882c9dba02fc44abbb950537a7caef510d
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://bd43e6e6de5440d2e3fa7319669e7dd730fdc72d124573af41bdbd3ed2c9a718
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:50:17Z"
      name: kube-rbac-proxy-main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:40Z"
    - containerID: containerd://ccd09c58391f6ce59f614f329d459198854de1e8ef59dc05bbf2ec9ad898f7f9
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://7e1cb76a6c1e7af69e947a17b501bdbab2c30ca4374b969374de8c726889d4b7
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:50:17Z"
      name: kube-rbac-proxy-self
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:41Z"
    - containerID: containerd://41d677bae85eada71a6348e645385866e420595130efcc2f8c6fa440be094185
      image: docker.io/kubesphere/kube-state-metrics:v2.6.0
      imageID: docker.io/kubesphere/kube-state-metrics@sha256:bdab4e49d71d272cf944c8612dff5ab1250f0fafdae45c22980286ac0c016032
      lastState:
        terminated:
          containerID: containerd://6a3016989558b0c8e27169c7a21c8e5be11d16121fe1316e14a1d092e4bb59b5
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:50:17Z"
      name: kube-state-metrics
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:40Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.217
    podIPs:
    - ip: 192.168.3.217
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-10T07:02:11Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 7f57ff6bf5
      pod-template-generation: "1"
    name: node-exporter-8c59f
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: 57c8536a-cdea-4fe5-840d-c6f0289d5d7b
    resourceVersion: "70961466"
    uid: 4bb0547b-4ec5-4925-addd-56866feacd41
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi02
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --no-collector.hwmon
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
      image: prom/node-exporter:v1.3.1
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 102m
          memory: 180Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jnkhc
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9100/
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 20Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jnkhc
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - name: kube-api-access-jnkhc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:48Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:12Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-10T07:02:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9efb6713afab7175248274da311434d48e67e7d1675900070f1e5eb12649749c
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState:
        terminated:
          containerID: containerd://f3ee98b06423f79fb6885344eb04bb317e3b9de8a77de541320acf9b638a8903
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:20:18Z"
      name: kube-rbac-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:30:48Z"
    - containerID: containerd://9dbc60bf9b503fa8a3b2a1eaee1c5a1ab61a567fa32129b83f9766ac084bf4af
      image: docker.io/prom/node-exporter:v1.3.1
      imageID: docker.io/prom/node-exporter@sha256:f2269e73124dd0f60a7d19a2ce1264d33d08a985aed0ee6b0b89d0be470592cd
      lastState:
        terminated:
          containerID: containerd://618c6fff5147ca3fe9d76fbeb0678d84f20d75aef8370bd4bad2762f255db171
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:20:18Z"
      name: node-exporter
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:30:46Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 10.48.219.139
    podIPs:
    - ip: 10.48.219.139
    qosClass: Burstable
    startTime: "2025-02-10T07:02:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:40:17Z"
    generateName: notification-manager-deployment-c9d789f99-
    labels:
      app: notification-manager
      notification-manager: notification-manager
      pod-template-hash: c9d789f99
    name: notification-manager-deployment-c9d789f99-785kq
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: notification-manager-deployment-c9d789f99
      uid: fceec78a-ae96-4af7-bfb1-a1732e1ad323
    resourceVersion: "70971663"
    uid: dff6d041-b68f-49d1-b17b-4c5324ca28a5
  spec:
    affinity: {}
    containers:
    - env:
      - name: NAMESPACE
        value: kubesphere-monitoring-federated
      image: kubesphere/notification-manager:v2.3.0
      imagePullPolicy: IfNotPresent
      name: notification-manager
      ports:
      - containerPort: 19093
        name: webhook
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 500Mi
        requests:
          cpu: 5m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-99jcd
        readOnly: true
    - image: kubesphere/notification-tenant-sidecar:v3.2.0
      imagePullPolicy: IfNotPresent
      name: tenant
      ports:
      - containerPort: 19094
        name: tenant
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-99jcd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: notification-manager-sa
    serviceAccountName: notification-manager-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-99jcd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:02Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:09:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:09:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7dfae675832714888f4eab7548ce8286cc994012d51c67dfbbd79994034d24b9
      image: docker.io/kubesphere/notification-manager:v2.3.0
      imageID: docker.io/kubesphere/notification-manager@sha256:8a208b905cfc4620832d9e4807e6390cfa27b8ec5e8d0ebd0f1a781503b7fc34
      lastState:
        terminated:
          containerID: containerd://2cce364318f235c02fd93cf70f2ef7d6e6b3dcfce7305f1fd27832caa3c9859d
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:46:05Z"
      name: notification-manager
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:55Z"
    - containerID: containerd://5075509da1b1d112d4f9b041a3338f455ea0e00fcc63edc8a6616def3deec9a1
      image: docker.io/kubesphere/notification-tenant-sidecar:v3.2.0
      imageID: docker.io/kubesphere/notification-tenant-sidecar@sha256:32c98dac712c0b08bd1e16dc3fb5a2241d5a0f8580f8f92b2a53c83d0cae2578
      lastState:
        terminated:
          containerID: containerd://99a7226b6b73edcc06d6a8964744d2138141fb8c6bdec92b4e4008b90b13e4ec
          exitCode: 1
          finishedAt: "2025-06-20T21:04:16Z"
          reason: Error
          startedAt: "2025-06-20T21:04:16Z"
      name: tenant
      ready: true
      restartCount: 16
      started: true
      state:
        running:
          startedAt: "2025-06-20T21:09:26Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.224
    podIPs:
    - ip: 192.168.3.224
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:40:17Z"
    generateName: notification-manager-operator-9949f4878-
    labels:
      control-plane: controller-manager
      pod-template-hash: 9949f4878
    name: notification-manager-operator-9949f4878-x9vqw
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: notification-manager-operator-9949f4878
      uid: 4764bed3-304c-4992-b336-dcea8b5c0305
    resourceVersion: "70961442"
    uid: 5686fda7-525b-4379-86f0-e0cd41e0125d
  spec:
    affinity: {}
    containers:
    - args:
      - --secure-listen-address=0.0.0.0:8443
      - --upstream=http://127.0.0.1:8080/
      - --logtostderr=true
      - --v=10
      image: kubesphere/kube-rbac-proxy:v0.11.0
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources:
        limits:
          cpu: 50m
          memory: 50Mi
        requests:
          cpu: 5m
          memory: 10Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9rrfp
        readOnly: true
    - args:
      - --metrics-addr=127.0.0.1:8080
      - --enable-leader-election
      command:
      - /notification-manager-operator
      env:
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: kubesphere/notification-manager-operator:v2.3.0
      imagePullPolicy: IfNotPresent
      name: notification-manager-operator
      ports:
      - containerPort: 9443
        name: webhook-server
        protocol: TCP
      resources:
        limits:
          cpu: 50m
          memory: 50Mi
        requests:
          cpu: 5m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/k8s-webhook-server/serving-certs
        name: cert
        readOnly: true
      - mountPath: /etc/localtime
        name: host-time
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9rrfp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: notification-manager-sa
    serviceAccountName: notification-manager-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: cert
      secret:
        defaultMode: 420
        secretName: notification-manager-webhook-server-cert
    - hostPath:
        path: /etc/localtime
        type: ""
      name: host-time
    - name: kube-api-access-9rrfp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5966853002ef97ae2509ae5c056eafb9241a5152cb2fd1eea8f5c74d989b453a
      image: docker.io/kubesphere/kube-rbac-proxy:v0.11.0
      imageID: docker.io/kubesphere/kube-rbac-proxy@sha256:0df4ae70e3bd0feffcec8f5cdb428f4abe666b667af991269ec5cb0bbda65869
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:40Z"
    - containerID: containerd://94b71db3d870e85df357c0e20d438057f514a83148adb54b3a68b58d98eb43c1
      image: docker.io/kubesphere/notification-manager-operator:v2.3.0
      imageID: docker.io/kubesphere/notification-manager-operator@sha256:a7c3671f5c15d1f24f822f01de997d4bff78700e52290f94da8be80927e09a94
      lastState:
        terminated:
          containerID: containerd://db133e4333d1660e4564736fa56fa1cfa71713cc42207e363732fcb68df08a21
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-06-20T20:21:12Z"
      name: notification-manager-operator
      ready: true
      restartCount: 6
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:41Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.219
    podIPs:
    - ip: 192.168.3.219
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: prometheus
    creationTimestamp: "2025-06-20T20:42:57Z"
    generateName: prometheus-k8s-
    labels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 2.39.1
      apps.kubernetes.io/pod-index: "1"
      controller-revision-hash: prometheus-k8s-745fccb79c
      operator.prometheus.io/name: k8s
      operator.prometheus.io/shard: "0"
      prometheus: k8s
      statefulset.kubernetes.io/pod-name: prometheus-k8s-1
    name: prometheus-k8s-1
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-k8s
      uid: 5d38d7dc-8f61-4eb2-81b7-07cb7d961443
    resourceVersion: "70961763"
    uid: b96580f1-5e2d-4d9b-b984-ee7ed9d830c6
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/monitoring
              operator: Exists
          weight: 100
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: prometheus
                app.kubernetes.io/instance: k8s
                app.kubernetes.io/name: prometheus
                app.kubernetes.io/part-of: kube-prometheus
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --storage.tsdb.retention.time=7d
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
      - --query.max-concurrency=1000
      - --web.route-prefix=/
      - --web.config.file=/etc/prometheus/web_config/web-config.yaml
      image: prom/prometheus:v2.39.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /-/healthy
          port: web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      name: prometheus
      ports:
      - containerPort: 9090
        name: web
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        limits:
          cpu: "4"
          memory: 16Gi
        requests:
          cpu: 200m
          memory: 400Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /-/ready
          port: web
          scheme: HTTP
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/prometheus/certs
        name: tls-assets
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-k8s-db
        subPath: prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /etc/prometheus/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-m8zc5
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-m8zc5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-k8s-1
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8080
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-m8zc5
        readOnly: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 0
      runAsNonRoot: false
      runAsUser: 0
    serviceAccount: prometheus-k8s
    serviceAccountName: prometheus-k8s
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoSchedule
      key: dedicated
      operator: Equal
      value: monitoring
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: prometheus-k8s-db
      persistentVolumeClaim:
        claimName: prometheus-k8s-db-prometheus-k8s-1
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: prometheus-k8s-tls-assets-0
    - emptyDir: {}
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-k8s-rulefiles-0
      name: prometheus-k8s-rulefiles-0
    - name: web-config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-web-config
    - name: kube-api-access-m8zc5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:23Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:37Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:37Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:42:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://163663182cffc9b41e38986e81dbe9f4aa23e577863e9b0d85ccc42bbc2213e4
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:43:23Z"
    - containerID: containerd://63de1855f7296a205d3950d190d8426768b7e3a8e54e404ae2b72a21ec8d1c93
      image: docker.io/prom/prometheus:v2.39.1
      imageID: docker.io/prom/prometheus@sha256:4748e26f9369ee7270a7cd3fb9385c1adb441c05792ce2bce2f6dd622fd91d38
      lastState: {}
      name: prometheus
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:43:23Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    initContainerStatuses:
    - containerID: containerd://cce7e488d543d9e3ffd38fc90a5010efe6f47082c20fcedfc692ebd762dc2900
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://cce7e488d543d9e3ffd38fc90a5010efe6f47082c20fcedfc692ebd762dc2900
          exitCode: 0
          finishedAt: "2025-06-20T20:43:22Z"
          reason: Completed
          startedAt: "2025-06-20T20:43:22Z"
    phase: Running
    podIP: 192.168.3.242
    podIPs:
    - ip: 192.168.3.242
    qosClass: Burstable
    startTime: "2025-06-20T20:43:17Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: thanos-ruler
    creationTimestamp: "2025-04-16T11:40:24Z"
    generateName: thanos-ruler-kubesphere-
    labels:
      app.kubernetes.io/component: thanos-ruler
      app.kubernetes.io/instance: kubesphere
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: thanos-ruler
      app.kubernetes.io/part-of: kube-prometheus
      app.kubernetes.io/version: 0.31.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: thanos-ruler-kubesphere-7d97bc46ff
      statefulset.kubernetes.io/pod-name: thanos-ruler-kubesphere-0
      thanos-ruler: kubesphere
    name: thanos-ruler-kubesphere-0
    namespace: kubesphere-monitoring-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: thanos-ruler-kubesphere
      uid: 7515b72f-709c-4a9c-822d-fcdbc676e0dc
    resourceVersion: "70963305"
    uid: ff212f55-b536-4c2e-9b19-0e6d66e396d7
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: thanos-ruler
                app.kubernetes.io/instance: kubesphere
                app.kubernetes.io/name: thanos-ruler
                app.kubernetes.io/part-of: kube-prometheus
            namespaces:
            - kubesphere-monitoring-system
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - rule
      - --data-dir=/thanos/data
      - --eval-interval=1m
      - --tsdb.retention=24h
      - --label=thanos_ruler_replica="$(POD_NAME)"
      - --alert.label-drop=thanos_ruler_replica
      - --query=http://prometheus-operated.kubesphere-monitoring-system.svc:9090
      - --rule-file=/etc/thanos/rules/*/*.yaml
      - --alertmanagers.url=dnssrv+http://alertmanager-operated.kubesphere-monitoring-system.svc:9093
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      image: thanosio/thanos:v0.31.0
      imagePullPolicy: IfNotPresent
      name: thanos-ruler
      ports:
      - containerPort: 10901
        name: grpc
        protocol: TCP
      - containerPort: 10902
        name: web
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /thanos/data
        name: thanos-ruler-kubesphere-data
      - mountPath: /etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
        name: thanos-ruler-kubesphere-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lrpkk
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://localhost:10902/-/reload
      - --watched-dir=/etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: kubesphere/prometheus-config-reloader:v0.55.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
        name: thanos-ruler-kubesphere-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lrpkk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: thanos-ruler-kubesphere-0
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: thanos-ruler-kubesphere-rulefiles-0
      name: thanos-ruler-kubesphere-rulefiles-0
    - emptyDir: {}
      name: thanos-ruler-kubesphere-data
    - name: kube-api-access-lrpkk
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:04Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:48:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:48:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e954843c2ef93c16af01894d649168fc2181f1a40b3a687cbf0aee75ef1e5b02
      image: docker.io/kubesphere/prometheus-config-reloader:v0.55.1
      imageID: docker.io/kubesphere/prometheus-config-reloader@sha256:77c5a31bd7ac72a4b3ba3a6d3aa8e593eb070bd61384c49e96ad3d4aa0aa185d
      lastState:
        terminated:
          containerID: containerd://96db9ea893e371b7eb861853f58eccfbc7f0c0a7da9579d0d336f81a3a03fe91
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          message: |
            level=info ts=2025-04-16T12:48:35.24843867Z caller=main.go:111 msg="Starting prometheus-config-reloader" version="(version=0.55.1, branch=refs/tags/v0.55.1, revision=08c846115c67195bc821018168040db6f3e236e3)"
            level=info ts=2025-04-16T12:48:35.248503274Z caller=main.go:112 build_context="(go=go1.17.7, user=Action-Run-ID-2045821452, date=20220326-21:47:32)"
            level=info ts=2025-04-16T12:48:35.248760017Z caller=main.go:149 msg="Starting web server for metrics" listen=:8080
            level=info ts=2025-04-16T12:48:35.24887646Z caller=reloader.go:235 msg="started watching config file and directories for changes" cfg= out= dirs=/etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
            level=info ts=2025-04-16T12:51:35.441256588Z caller=reloader.go:373 msg="Reload triggered" cfg_in= cfg_out= watched_dirs=/etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
            level=info ts=2025-04-25T07:53:07.3180103Z caller=reloader.go:373 msg="Reload triggered" cfg_in= cfg_out= watched_dirs=/etc/thanos/rules/thanos-ruler-kubesphere-rulefiles-0
          reason: Unknown
          startedAt: "2025-04-16T12:48:35Z"
      name: config-reloader
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:04Z"
    - containerID: containerd://b8b21ae2e573dabaa108f28ccbac1374505d0d4ca27aff645216ecbc95682b56
      image: docker.io/thanosio/thanos:v0.31.0
      imageID: docker.io/thanosio/thanos@sha256:e7d337d6ac2aea3f0f9314ec9830291789e16e2b480b9d353be02d05ce7f2a7e
      lastState:
        terminated:
          containerID: containerd://32f8b6e54b04c4f9993254b3d7739385992a2df1b9fbd3998756e2960ee885f5
          exitCode: 1
          finishedAt: "2025-06-20T20:42:58Z"
          message: |
            ller=http.go:110 component=rules service=http/server component=rule msg="internal server is shutdown gracefully" err="lookup SRV records \"alertmanager-operated.kubesphere-monitoring-system.svc\": could not resolve \"alertmanager-operated.kubesphere-monitoring-system.svc\": all servers responded with errors to at least one search domain. Errs ;could not resolve alertmanager-operated.kubesphere-monitoring-system.svc.: no servers returned a viable answer. Errs ;resolution against server 10.96.0.10 for alertmanager-operated.kubesphere-monitoring-system.svc.: exchange: read udp 192.168.3.227:47648->10.96.0.10:53: i/o timeout"
            level=info ts=2025-06-20T20:42:58.143203597Z caller=intrumentation.go:81 component=rules msg="changing probe status" status=not-healthy reason="lookup SRV records \"alertmanager-operated.kubesphere-monitoring-system.svc\": could not resolve \"alertmanager-operated.kubesphere-monitoring-system.svc\": all servers responded with errors to at least one search domain. Errs ;could not resolve alertmanager-operated.kubesphere-monitoring-system.svc.: no servers returned a viable answer. Errs ;resolution against server 10.96.0.10 for alertmanager-operated.kubesphere-monitoring-system.svc.: exchange: read udp 192.168.3.227:47648->10.96.0.10:53: i/o timeout"
            level=error ts=2025-06-20T20:42:58.143264201Z caller=main.go:161 err="lookup SRV records \"alertmanager-operated.kubesphere-monitoring-system.svc\": could not resolve \"alertmanager-operated.kubesphere-monitoring-system.svc\": all servers responded with errors to at least one search domain. Errs ;could not resolve alertmanager-operated.kubesphere-monitoring-system.svc.: no servers returned a viable answer. Errs ;resolution against server 10.96.0.10 for alertmanager-operated.kubesphere-monitoring-system.svc.: exchange: read udp 192.168.3.227:47648->10.96.0.10:53: i/o timeout\nrule command failed\nmain.main\n\t/app/cmd/thanos/main.go:161\nruntime.main\n\t/usr/local/go/src/runtime/proc.go:250\nruntime.goexit\n\t/usr/local/go/src/runtime/asm_amd64.s:1594"
          reason: Error
          startedAt: "2025-06-20T20:38:26Z"
      name: thanos-ruler
      ready: true
      restartCount: 26
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:48:08Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.227
    podIPs:
    - ip: 192.168.3.227
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-06-20T20:32:06Z"
    generateName: ks-apiserver-945bb6c8c-
    labels:
      app: ks-apiserver
      pod-template-hash: 945bb6c8c
      tier: backend
    name: ks-apiserver-945bb6c8c-dr2pf
    namespace: kubesphere-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ks-apiserver-945bb6c8c
      uid: cf6cb267-a809-4ee4-82ab-877adc7ba7e1
    resourceVersion: "70961414"
    uid: dad2c469-d2d2-4c88-a311-775b111bb67e
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/master
              operator: In
              values:
              - ""
          weight: 100
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - ks-apiserver
          namespaces:
          - kubesphere-system
          topologyKey: kubernetes.io/hostname
    containers:
    - command:
      - ks-apiserver
      - --logtostderr=true
      image: kubesphere/ks-apiserver:v3.4.1
      imagePullPolicy: Always
      livenessProbe:
        failureThreshold: 8
        httpGet:
          path: /healthz
          port: 9090
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: ks-apiserver
      ports:
      - containerPort: 9090
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 20m
          memory: 100Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubesphere/ingress-controller
        name: ks-router-config
      - mountPath: /etc/kubesphere/
        name: kubesphere-config
      - mountPath: /etc/localtime
        name: host-time
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mwxgh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubesphere
    serviceAccountName: kubesphere
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 60
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 60
    volumes:
    - configMap:
        defaultMode: 420
        name: ks-router-config
      name: ks-router-config
    - configMap:
        defaultMode: 420
        name: kubesphere-config
      name: kubesphere-config
    - hostPath:
        path: /etc/localtime
        type: ""
      name: host-time
    - name: kube-api-access-mwxgh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:39Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:39Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:39Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f9ebbaa448c235e7521afbff2b5284f68c451bbd6f7293703da93a2822a62835
      image: docker.io/kubesphere/ks-apiserver:v3.4.1
      imageID: docker.io/kubesphere/ks-apiserver@sha256:2cc1e398fcd087d1ea857db440d9251e4bfc8ec0fa42dbaa397b56987990c976
      lastState: {}
      name: ks-apiserver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:38Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.237
    podIPs:
    - ip: 192.168.3.237
    qosClass: Burstable
    startTime: "2025-06-20T20:32:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-06-20T20:32:06Z"
    generateName: ks-console-7bcbf87f4-
    labels:
      app: ks-console
      pod-template-hash: 7bcbf87f4
      tier: frontend
    name: ks-console-7bcbf87f4-snqbp
    namespace: kubesphere-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ks-console-7bcbf87f4
      uid: d0603ce7-64eb-4ecb-a8fb-082c0657594d
    resourceVersion: "70961425"
    uid: 197d7834-7e85-4516-bc2b-7c0213e9697d
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/master
              operator: In
              values:
              - ""
          weight: 100
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - ks-console
          namespaces:
          - kubesphere-system
          topologyKey: kubernetes.io/hostname
    containers:
    - image: kubesphere/ks-console:v3.4.1
      imagePullPolicy: Always
      livenessProbe:
        failureThreshold: 8
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: 8000
        timeoutSeconds: 15
      name: ks-console
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 20m
          memory: 100Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/kubesphere/console/server/local_config.yaml
        name: ks-console-config
        subPath: local_config.yaml
      - mountPath: /opt/kubesphere/console/server/sample
        name: sample-bookinfo
      - mountPath: /etc/localtime
        name: host-time
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-drlzs
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubesphere
    serviceAccountName: kubesphere
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 60
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 60
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: local_config.yaml
          path: local_config.yaml
        name: ks-console-config
      name: ks-console-config
    - configMap:
        defaultMode: 420
        name: sample-bookinfo
      name: sample-bookinfo
    - hostPath:
        path: /etc/localtime
        type: ""
      name: host-time
    - name: kube-api-access-drlzs
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:43Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:43Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:43Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c0b9523f347b073ba377f697be3c9e8fab836c2248ad10bbfb559db995c14bc8
      image: docker.io/kubesphere/ks-console:v3.4.1
      imageID: docker.io/kubesphere/ks-console@sha256:8f673616acd6653ffc4e09f4766da15bbeefb84649e28f66155cbedb4d743562
      lastState: {}
      name: ks-console
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:42Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.236
    podIPs:
    - ip: 192.168.3.236
    qosClass: Burstable
    startTime: "2025-06-20T20:32:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-06-20T20:32:06Z"
    generateName: ks-controller-manager-6c9757d557-
    labels:
      app: ks-controller-manager
      pod-template-hash: 6c9757d557
      tier: backend
    name: ks-controller-manager-6c9757d557-wqqf2
    namespace: kubesphere-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ks-controller-manager-6c9757d557
      uid: 61dd2568-2a2e-428a-9f9c-92eea4e1d4f9
    resourceVersion: "122982578"
    uid: 7db78378-22bf-40ae-a316-2436099dc10f
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/master
              operator: In
              values:
              - ""
          weight: 100
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - ks-controller-manager
          namespaces:
          - kubesphere-system
          topologyKey: kubernetes.io/hostname
    containers:
    - command:
      - controller-manager
      - --logtostderr=true
      - --leader-elect=true
      image: kubesphere/ks-controller-manager:v3.4.1
      imagePullPolicy: Always
      name: ks-controller-manager
      ports:
      - containerPort: 8080
        protocol: TCP
      - containerPort: 8443
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 1000Mi
        requests:
          cpu: 30m
          memory: 50Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubesphere/
        name: kubesphere-config
      - mountPath: /tmp/k8s-webhook-server/serving-certs
        name: webhook-secret
      - mountPath: /etc/localtime
        name: host-time
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5x5zm
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubesphere
    serviceAccountName: kubesphere
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 60
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 60
    volumes:
    - configMap:
        defaultMode: 420
        name: kubesphere-config
      name: kubesphere-config
    - name: webhook-secret
      secret:
        defaultMode: 420
        secretName: ks-controller-manager-webhook-cert
    - hostPath:
        path: /etc/localtime
        type: ""
      name: host-time
    - name: kube-api-access-5x5zm
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:45Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-07-31T01:22:39Z"
      message: 'containers with unready status: [ks-controller-manager]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-07-31T01:22:39Z"
      message: 'containers with unready status: [ks-controller-manager]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://568dcc9b579d6d7c8d154b5e64202a165998361864a2fbc817071dc2ca6a1c63
      image: docker.io/kubesphere/ks-controller-manager:v3.4.1
      imageID: docker.io/kubesphere/ks-controller-manager@sha256:2117332c7313755993bf4d91e50d9f0b4b109f307962af34864786c7aba30a1b
      lastState:
        terminated:
          containerID: containerd://568dcc9b579d6d7c8d154b5e64202a165998361864a2fbc817071dc2ca6a1c63
          exitCode: 255
          finishedAt: "2025-07-31T01:22:38Z"
          reason: Error
          startedAt: "2025-07-03T00:44:42Z"
      name: ks-controller-manager
      ready: false
      restartCount: 1
      started: false
      state:
        waiting:
          message: Back-off pulling image "kubesphere/ks-controller-manager:v3.4.1"
          reason: ImagePullBackOff
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.238
    podIPs:
    - ip: 192.168.3.238
    qosClass: Burstable
    startTime: "2025-06-20T20:32:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:40:19Z"
    generateName: ks-installer-6647685479-
    labels:
      app: ks-installer
      pod-template-hash: "6647685479"
    name: ks-installer-6647685479-6gs9f
    namespace: kubesphere-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ks-installer-6647685479
      uid: f768a3cc-1b03-40cc-818e-89b20b30fec4
    resourceVersion: "70972004"
    uid: 9436dd16-8fd8-4cd6-86e1-b851f9a9bb8b
  spec:
    containers:
    - image: kubesphere/ks-installer:v3.4.1
      imagePullPolicy: Always
      name: installer
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 20m
          memory: 100Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/localtime
        name: host-time
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ltmh8
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: ks-installer
    serviceAccountName: ks-installer
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /etc/localtime
        type: ""
      name: host-time
    - name: kube-api-access-ltmh8
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:12Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:10:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T21:10:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://afa96e6ae8d61a371185259d6768fa95c007b5148bd4ab2c18100b661c9e84e8
      image: docker.io/kubesphere/ks-installer:v3.4.1
      imageID: docker.io/kubesphere/ks-installer@sha256:ddb86c5268ff1ed909c4431f06a86a13cda771d5a39ead777c06efadd1acc74a
      lastState:
        terminated:
          containerID: containerd://63cf155a5d3c1072eefb6706a3f186e6eb816114e1b5913f898835f74264aa11
          exitCode: 1
          finishedAt: "2025-06-20T21:05:22Z"
          reason: Error
          startedAt: "2025-06-20T21:05:18Z"
      name: installer
      ready: true
      restartCount: 12
      started: true
      state:
        running:
          startedAt: "2025-06-20T21:10:25Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.220
    podIPs:
    - ip: 192.168.3.220
    qosClass: Burstable
    startTime: "2025-04-16T12:45:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-07T11:54:08Z"
    generateName: engine-image-ei-c2d50bcc-
    labels:
      controller-revision-hash: 7756674b54
      longhorn.io/component: engine-image
      longhorn.io/engine-image: ei-c2d50bcc
      pod-template-generation: "1"
    name: engine-image-ei-c2d50bcc-rqwsm
    namespace: longhorn-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: engine-image-ei-c2d50bcc
      uid: 4b34fb1e-37b9-41e6-9118-22d87258c47d
    resourceVersion: "70961494"
    uid: 50bde924-ce5f-4660-af2a-6059a52c5eab
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi02
    containers:
    - args:
      - -c
      - diff /usr/local/bin/longhorn /data/longhorn > /dev/null 2>&1; if [ $? -ne
        0 ]; then cp -p /usr/local/bin/longhorn /data/ && echo installed; fi && trap
        'rm /data/longhorn* && echo cleaned up' EXIT && sleep infinity
      command:
      - /bin/bash
      image: longhornio/longhorn-engine:v1.8.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - sh
          - -c
          - /data/longhorn version --client-only
        failureThreshold: 3
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 4
      name: engine-image-ei-c2d50bcc
      readinessProbe:
        exec:
          command:
          - sh
          - -c
          - ls /data/longhorn && /data/longhorn version --client-only
        failureThreshold: 3
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 4
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /data/
        name: data
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-qzkgf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 1000000000
    priorityClassName: longhorn-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: longhorn-service-account
    serviceAccountName: longhorn-service-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/longhorn/engine-binaries/longhornio-longhorn-engine-v1.8.0
        type: ""
      name: data
    - name: kube-api-access-qzkgf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T11:54:07Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:52Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:52Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T11:54:08Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://6dc20c6138d46359dc25339c3c56fba2ce014bbf8e50773b1b1bac8bf929c53f
      image: docker.io/longhornio/longhorn-engine:v1.8.0
      imageID: docker.io/longhornio/longhorn-engine@sha256:e4d94d4026c3508d3c68b46e7c82c41c76cf3ec533a8430f6144170a555b8965
      lastState:
        terminated:
          containerID: containerd://31708d6928560bf4ea91f5161759d0ab385601e1fe60d88d461e346e7d8a5326
          exitCode: 137
          finishedAt: "2025-06-20T20:32:47Z"
          reason: Error
          startedAt: "2025-06-20T20:32:04Z"
      name: engine-image-ei-c2d50bcc
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:48Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.232
    podIPs:
    - ip: 192.168.3.232
    qosClass: BestEffort
    startTime: "2025-02-07T11:54:07Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      longhorn.io/last-applied-tolerations: '[]'
    creationTimestamp: "2025-06-20T20:36:11Z"
    labels:
      longhorn.io/component: instance-manager
      longhorn.io/data-engine: v1
      longhorn.io/instance-manager-image: imi-46d35c0a
      longhorn.io/instance-manager-type: aio
      longhorn.io/managed-by: longhorn-manager
      longhorn.io/node: zee8608workerapi02
    name: instance-manager-cebb946b3b3be3279c2f59f7e76f53b9
    namespace: longhorn-system
    ownerReferences:
    - apiVersion: longhorn.io/v1beta2
      blockOwnerDeletion: true
      controller: true
      kind: InstanceManager
      name: instance-manager-cebb946b3b3be3279c2f59f7e76f53b9
      uid: f4d45888-5f24-4fcf-b863-fcf5dc4ca336
    resourceVersion: "70961432"
    uid: 681b0f4b-e5dc-43b4-8d6a-d72a4e3dc65f
  spec:
    containers:
    - args:
      - instance-manager
      - --debug
      - daemon
      - --listen
      - 0.0.0.0:8500
      env:
      - name: TLS_DIR
        value: /tls-files/
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: longhornio/longhorn-instance-manager:v1.8.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - test $(nc -zv localhost 8500 > /dev/null 2>&1 && nc -zv localhost 8501
            > /dev/null 2>&1 && nc -zv localhost 8502 > /dev/null 2>&1 && nc -zv localhost
            8503 > /dev/null 2>&1; echo $?) -eq 0
        failureThreshold: 6
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 4
      name: instance-manager
      resources:
        requests:
          cpu: 1440m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host
      - mountPath: /engine-binaries/
        mountPropagation: HostToContainer
        name: engine-binaries
      - mountPath: /host/var/lib/longhorn/unix-domain-socket/
        name: unix-domain-socket
      - mountPath: /tls-files/
        name: longhorn-grpc-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mvb6q
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 1000000000
    priorityClassName: longhorn-critical
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: longhorn-service-account
    serviceAccountName: longhorn-service-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /
        type: ""
      name: host
    - hostPath:
        path: /var/lib/longhorn/engine-binaries/
        type: ""
      name: engine-binaries
    - hostPath:
        path: /var/lib/longhorn/unix-domain-socket/
        type: ""
      name: unix-domain-socket
    - name: longhorn-grpc-tls
      secret:
        defaultMode: 420
        optional: true
        secretName: longhorn-grpc-tls
    - name: kube-api-access-mvb6q
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:36:12Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:36:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:36:12Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:36:12Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:36:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://051c964c905efd039a25ed92bafe70b536a3f8a369125841f7cd1b737a58cd8f
      image: docker.io/longhornio/longhorn-instance-manager:v1.8.0
      imageID: docker.io/longhornio/longhorn-instance-manager@sha256:411804ef7be19d4b303728dcbef0462e88f813233b932f2a89b6d1942dcace76
      lastState: {}
      name: instance-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:36:12Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.239
    podIPs:
    - ip: 192.168.3.239
    qosClass: Burstable
    startTime: "2025-06-20T20:36:11Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-02-09T01:36:23+05:30"
    creationTimestamp: "2025-02-08T20:06:26Z"
    generateName: longhorn-csi-plugin-
    labels:
      app: longhorn-csi-plugin
      controller-revision-hash: 5bf48968d4
      pod-template-generation: "2"
    name: longhorn-csi-plugin-6dcgc
    namespace: longhorn-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: longhorn-csi-plugin
      uid: 4878d8bb-13dd-4fba-867a-338d2fb13af6
    resourceVersion: "70961477"
    uid: 79a01914-b03a-44f8-8c23-311420045645
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi02
    containers:
    - args:
      - --v=2
      - --csi-address=$(ADDRESS)
      - --kubelet-registration-path=/var/lib/kubelet/plugins/driver.longhorn.io/csi.sock
      env:
      - name: ADDRESS
        value: /csi/csi.sock
      image: longhornio/csi-node-driver-registrar:v2.13.0
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/sh
            - -c
            - rm -rf /registration/driver.longhorn.io /registration/driver.longhorn.io-reg.sock
              /csi//*
      name: node-driver-registrar
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /csi/
        name: socket-dir
      - mountPath: /registration
        name: registration-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tk9zz
        readOnly: true
    - args:
      - --v=4
      - --csi-address=/csi/csi.sock
      image: longhornio/livenessprobe:v2.15.0
      imagePullPolicy: IfNotPresent
      name: longhorn-liveness-probe
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /csi/
        name: socket-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tk9zz
        readOnly: true
    - args:
      - longhorn-manager
      - -d
      - csi
      - --nodeid=$(NODE_ID)
      - --endpoint=$(CSI_ENDPOINT)
      - --drivername=driver.longhorn.io
      - --manager-url=http://longhorn-backend:9500/v1
      env:
      - name: NODE_ID
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CSI_ENDPOINT
        value: unix:///csi/csi.sock
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: longhornio/longhorn-manager:v1.8.0
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/sh
            - -c
            - rm -f /csi//*
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 9808
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 4
      name: longhorn-csi-plugin
      ports:
      - containerPort: 9808
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          add:
          - SYS_ADMIN
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /csi/
        name: socket-dir
      - mountPath: /var/lib/kubelet/plugins/kubernetes.io/csi
        mountPropagation: Bidirectional
        name: kubernetes-csi-dir
      - mountPath: /var/lib/kubelet/pods
        mountPropagation: Bidirectional
        name: pods-mount-dir
      - mountPath: /dev
        name: host-dev
      - mountPath: /host/proc
        name: host-proc
      - mountPath: /sys
        name: host-sys
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tk9zz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 1000000000
    priorityClassName: longhorn-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: longhorn-service-account
    serviceAccountName: longhorn-service-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/kubelet/plugins/kubernetes.io/csi
        type: DirectoryOrCreate
      name: kubernetes-csi-dir
    - hostPath:
        path: /var/lib/kubelet/plugins_registry
        type: DirectoryOrCreate
      name: registration-dir
    - hostPath:
        path: /var/lib/kubelet/plugins/driver.longhorn.io
        type: DirectoryOrCreate
      name: socket-dir
    - hostPath:
        path: /var/lib/kubelet/pods
        type: DirectoryOrCreate
      name: pods-mount-dir
    - hostPath:
        path: /dev
        type: ""
      name: host-dev
    - hostPath:
        path: /proc
        type: ""
      name: host-proc
    - hostPath:
        path: /sys
        type: ""
      name: host-sys
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-tk9zz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:55Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-08T20:06:27Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:40:00Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:40:00Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-08T20:06:27Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://dde58afe604b63489e2a631a3d4ba9930f6f983b65f977b92036ba252c9bc046
      image: docker.io/longhornio/longhorn-manager:v1.8.0
      imageID: docker.io/longhornio/longhorn-manager@sha256:3b8289b3e3bce156665748c3faa89b75a3f68b6bead377d708be544a70ed3b20
      lastState:
        terminated:
          containerID: containerd://f414df55d7f7491a82cab87ad2a07e89cc89f4d6c5756c654be075ee7cf2b0ab
          exitCode: 1
          finishedAt: "2025-06-20T20:35:08Z"
          reason: Error
          startedAt: "2025-06-20T20:34:58Z"
      name: longhorn-csi-plugin
      ready: true
      restartCount: 8
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:37:55Z"
    - containerID: containerd://8737bf8e544dd0464369752d3fe9584c7a3464fe5500fc22a533dcd902308098
      image: docker.io/longhornio/livenessprobe:v2.15.0
      imageID: docker.io/longhornio/livenessprobe@sha256:8ced2d04e57e44cfba0b9901e984d8f063c72133a1fde3eb607cc634cd2c8244
      lastState:
        terminated:
          containerID: containerd://0e5e5543d0e3cbd20bed1d91b24f1b1014a3b8854f2b99eacb4b569902662e4c
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:20:36Z"
      name: longhorn-liveness-probe
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:48Z"
    - containerID: containerd://dc65a12f8f48167b8eb5266664f3eed34aed84004b974148ebf543b703cf3181
      image: docker.io/longhornio/csi-node-driver-registrar:v2.13.0
      imageID: docker.io/longhornio/csi-node-driver-registrar@sha256:69cd0517dcd5ca916ad9c8297d3d5370df93c84619cec3d977e8770edf70874f
      lastState:
        terminated:
          containerID: containerd://05c472c0518406226d16292f21d43459103a9a296a9ac02fc0dfc81713f6202f
          exitCode: 1
          finishedAt: "2025-06-20T20:37:15Z"
          reason: Error
          startedAt: "2025-06-20T20:36:45Z"
      name: node-driver-registrar
      ready: true
      restartCount: 7
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:40:00Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.222
    podIPs:
    - ip: 192.168.3.222
    qosClass: BestEffort
    startTime: "2025-02-08T20:06:27Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-07T11:53:40Z"
    generateName: longhorn-manager-
    labels:
      app: longhorn-manager
      app.kubernetes.io/instance: longhorn
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: longhorn
      app.kubernetes.io/version: v1.8.0
      controller-revision-hash: 899d7b89b
      helm.sh/chart: longhorn-1.8.0
      longhorn.io/admission-webhook: longhorn-admission-webhook
      longhorn.io/conversion-webhook: longhorn-conversion-webhook
      longhorn.io/recovery-backend: longhorn-recovery-backend
      pod-template-generation: "1"
    name: longhorn-manager-4ckwk
    namespace: longhorn-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: longhorn-manager
      uid: 2db311a3-e5d4-4c19-b150-443eb97a1655
    resourceVersion: "70961453"
    uid: 363862a8-6a6d-44f2-8481-0b92e929fefb
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi02
    containers:
    - command:
      - longhorn-manager
      - -d
      - daemon
      - --engine-image
      - longhornio/longhorn-engine:v1.8.0
      - --instance-manager-image
      - longhornio/longhorn-instance-manager:v1.8.0
      - --share-manager-image
      - longhornio/longhorn-share-manager:v1.8.0
      - --backing-image-manager-image
      - longhornio/backing-image-manager:v1.8.0
      - --support-bundle-manager-image
      - longhornio/support-bundle-kit:v0.0.49
      - --manager-image
      - longhornio/longhorn-manager:v1.8.0
      - --service-account
      - longhorn-service-account
      - --upgrade-version-check
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: longhornio/longhorn-manager:v1.8.0
      imagePullPolicy: IfNotPresent
      name: longhorn-manager
      ports:
      - containerPort: 9500
        name: manager
        protocol: TCP
      - containerPort: 9501
        name: conversion-wh
        protocol: TCP
      - containerPort: 9502
        name: admission-wh
        protocol: TCP
      - containerPort: 9503
        name: recov-backend
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /v1/healthz
          port: 9501
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/boot/
        name: boot
        readOnly: true
      - mountPath: /host/dev/
        name: dev
      - mountPath: /host/proc/
        name: proc
        readOnly: true
      - mountPath: /host/etc/
        name: etc
        readOnly: true
      - mountPath: /var/lib/longhorn/
        mountPropagation: Bidirectional
        name: longhorn
      - mountPath: /tls-files/
        name: longhorn-grpc-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tnv66
        readOnly: true
    - command:
      - sh
      - -c
      - echo share-manager image pulled && sleep infinity
      image: longhornio/longhorn-share-manager:v1.8.0
      imagePullPolicy: IfNotPresent
      name: pre-pull-share-manager-image
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tnv66
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 1000000000
    priorityClassName: longhorn-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: longhorn-service-account
    serviceAccountName: longhorn-service-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /boot/
        type: ""
      name: boot
    - hostPath:
        path: /dev/
        type: ""
      name: dev
    - hostPath:
        path: /proc/
        type: ""
      name: proc
    - hostPath:
        path: /etc/
        type: ""
      name: etc
    - hostPath:
        path: /var/lib/longhorn/
        type: ""
      name: longhorn
    - name: longhorn-grpc-tls
      secret:
        defaultMode: 420
        optional: true
        secretName: longhorn-grpc-tls
    - name: kube-api-access-tnv66
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:10Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T11:53:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:36:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:36:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T11:53:40Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://89e2e031e3d200cce8e0f9e4e123943ba8ca2d94a2313b82ab2a444586f78bd1
      image: docker.io/longhornio/longhorn-manager:v1.8.0
      imageID: docker.io/longhornio/longhorn-manager@sha256:3b8289b3e3bce156665748c3faa89b75a3f68b6bead377d708be544a70ed3b20
      lastState:
        terminated:
          containerID: containerd://a6df7a3da320221f5ccaf9f61b36cc547f96cb13985f5ae4ac3ea0f1c4265249
          exitCode: 1
          finishedAt: "2025-06-20T20:35:26Z"
          reason: Error
          startedAt: "2025-06-20T20:34:24Z"
      name: longhorn-manager
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:36:07Z"
    - containerID: containerd://35b70351637906590a8b9c2e7e1586a8cf0912306b9e6a1d5f74545f6b37052e
      image: docker.io/longhornio/longhorn-share-manager:v1.8.0
      imageID: docker.io/longhornio/longhorn-share-manager@sha256:92c05080cb1589060b6c5c58f8012022b9a792aac6e548d122d2986dc84e53be
      lastState:
        terminated:
          containerID: containerd://d31f9e782ebc41a488898c120004a5501e03fb1012250be7cac8c4741731b80d
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:20:34Z"
      name: pre-pull-share-manager-image
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:09Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.235
    podIPs:
    - ip: 192.168.3.235
    qosClass: BestEffort
    startTime: "2025-02-07T11:53:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/port: "7472"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-02-07T11:07:41Z"
    generateName: speaker-
    labels:
      app: metallb
      component: speaker
      controller-revision-hash: 6c88db67c6
      pod-template-generation: "1"
    name: speaker-7m6cb
    namespace: metallb-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: speaker
      uid: d3416e4b-a93a-48a4-b43c-d1c4ac2fd037
    resourceVersion: "70961489"
    uid: 1add1e2c-ac1b-4734-9910-901ec1ea4d19
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - zee8608workerapi02
    containers:
    - args:
      - --port=7472
      - --log-level=info
      env:
      - name: METALLB_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: METALLB_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: METALLB_HOST
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      - name: METALLB_ML_BIND_ADDR
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: METALLB_ML_LABELS
        value: app=metallb,component=speaker
      - name: METALLB_ML_SECRET_KEY_PATH
        value: /etc/ml_secret_key
      image: quay.io/metallb/speaker:v0.14.9
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: monitoring
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: speaker
      ports:
      - containerPort: 7472
        hostPort: 7472
        name: monitoring
        protocol: TCP
      - containerPort: 7946
        hostPort: 7946
        name: memberlist-tcp
        protocol: TCP
      - containerPort: 7946
        hostPort: 7946
        name: memberlist-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: monitoring
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_RAW
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ml_secret_key
        name: memberlist
        readOnly: true
      - mountPath: /etc/metallb
        name: metallb-excludel2
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-czdzr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: zee8608workerapi02
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: speaker
    serviceAccountName: speaker
    terminationGracePeriodSeconds: 2
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: memberlist
      secret:
        defaultMode: 420
        secretName: memberlist
    - configMap:
        defaultMode: 256
        name: metallb-excludel2
      name: metallb-excludel2
    - name: kube-api-access-czdzr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:30:47Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T11:07:40Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:33Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:31:33Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T11:07:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7429fa6ed826a780e2eeefcc21e1b342d993cce0fc488c164b2b9503ff36528a
      image: quay.io/metallb/speaker:v0.14.9
      imageID: quay.io/metallb/speaker@sha256:b09a1dfcf330938950b65115cd58f6989108c0c21d3c096040e7fe9a25a92993
      lastState:
        terminated:
          containerID: containerd://c5ef3a2265a68e66716f074c232e024b148169dde82716b916f342eb6d1da10b
          exitCode: 137
          finishedAt: "2025-06-20T20:31:22Z"
          reason: Error
          startedAt: "2025-06-20T20:30:47Z"
      name: speaker
      ready: true
      restartCount: 4
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:31:22Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 10.48.219.139
    podIPs:
    - ip: 10.48.219.139
    qosClass: BestEffort
    startTime: "2025-02-07T11:07:40Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T07:52:11Z"
    generateName: cmsapi-deploy-f545f8c6d-
    labels:
      app: cmsapi-app
      environment: prod
      pod-template-hash: f545f8c6d
      project: zee-project
    name: cmsapi-deploy-f545f8c6d-vgx6b
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cmsapi-deploy-f545f8c6d
      uid: eb011958-9b3e-4597-a48b-6f761332a858
    resourceVersion: "122573904"
    uid: 53591bd3-0db0-41bb-968d-5cb7f70ae4a3
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: cmsapi-config
      - secretRef:
          name: cmsapi-secrets
      image: devzeelearn/cmsapi-prod:186
      imagePullPolicy: Always
      name: cmsapi
      ports:
      - containerPort: 5011
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 500m
          memory: 256Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-crhz6
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-crhz6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:52:47Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:51:33Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-10-02T11:45:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-10-02T11:45:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:52:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e3e11474aba78039a3ec5b08f05c371d6d389a7583516597c8685139d76b1d8f
      image: docker.io/devzeelearn/cmsapi-prod:186
      imageID: docker.io/devzeelearn/cmsapi-prod@sha256:bc4cf5e024c848264519cb970a0842aef124da1fc9960a0085687f9db5b75c7c
      lastState:
        terminated:
          containerID: containerd://2c992d1cbd269c7a288f500fa4469b4d73e09da9ac36f8fe4a56d85c0a8ac006
          exitCode: 1
          finishedAt: "2025-10-02T11:45:43Z"
          reason: Error
          startedAt: "2025-10-01T11:16:55Z"
      name: cmsapi
      ready: true
      restartCount: 65
      started: true
      state:
        running:
          startedAt: "2025-10-02T11:45:45Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.192
    podIPs:
    - ip: 192.168.3.192
    qosClass: Burstable
    startTime: "2025-09-20T07:51:33Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T07:53:29Z"
    generateName: graphql-deploy-98cc44b8b-
    labels:
      app: graphql-app
      environment: prod
      pod-template-hash: 98cc44b8b
      project: zee-project
    name: graphql-deploy-98cc44b8b-vndxg
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: graphql-deploy-98cc44b8b
      uid: 2c11f592-470c-4f4b-a86c-9e0cebabbc43
    resourceVersion: "121979727"
    uid: e91ea836-bd45-48de-9f2e-2f8327cddd10
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: graphql-config
      - secretRef:
          name: graphql-secrets
      image: devzeelearn/graphql-prod:17
      imagePullPolicy: Always
      name: graphql-prod
      ports:
      - containerPort: 5015
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 250m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-99cnp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-99cnp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:53:50Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:53:27Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-10-01T06:07:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-10-01T06:07:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:05Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7a93a4b0e59e0e0b8707e10f9a51407dd118c2bf09598c17e3e628c9b64e4d62
      image: docker.io/devzeelearn/graphql-prod:17
      imageID: docker.io/devzeelearn/graphql-prod@sha256:fe29bef2726d6170eeffc8d76e87a0627a8811fe00b87be4965add5ff36b9431
      lastState:
        terminated:
          containerID: containerd://444a26a1fb818c04d68acace04a5501ef0e81d085ac9133202d62f0970c6716d
          exitCode: 137
          finishedAt: "2025-10-01T06:07:17Z"
          reason: OOMKilled
          startedAt: "2025-09-26T04:52:10Z"
      name: graphql-prod
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2025-10-01T06:07:20Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.194
    podIPs:
    - ip: 192.168.3.194
    qosClass: Burstable
    startTime: "2025-09-20T07:53:27Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T07:54:28Z"
    generateName: graphql-deploy-98cc44b8b-
    labels:
      app: graphql-app
      environment: prod
      pod-template-hash: 98cc44b8b
      project: zee-project
    name: graphql-deploy-98cc44b8b-w4jgb
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: graphql-deploy-98cc44b8b
      uid: 2c11f592-470c-4f4b-a86c-9e0cebabbc43
    resourceVersion: "120992204"
    uid: 29e68fda-d677-4ec2-a7ca-341893208ce7
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: graphql-config
      - secretRef:
          name: graphql-secrets
      image: devzeelearn/graphql-prod:17
      imagePullPolicy: Always
      name: graphql-prod
      ports:
      - containerPort: 5015
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 250m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4ln6j
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-4ln6j
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:53:58Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:53:53Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-29T04:50:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-29T04:50:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:31Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://2b7b216b5289014b5ce16c2249992dc589ed495100ee0f49ee736f235323d2c6
      image: docker.io/devzeelearn/graphql-prod:17
      imageID: docker.io/devzeelearn/graphql-prod@sha256:fe29bef2726d6170eeffc8d76e87a0627a8811fe00b87be4965add5ff36b9431
      lastState:
        terminated:
          containerID: containerd://1acf029c511a2dba85e617963377c75f52c843efb884126d48d7abde88acb5d9
          exitCode: 137
          finishedAt: "2025-09-29T04:50:39Z"
          reason: OOMKilled
          startedAt: "2025-09-25T09:22:48Z"
      name: graphql-prod
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2025-09-29T04:50:41Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.196
    podIPs:
    - ip: 192.168.3.196
    qosClass: Burstable
    startTime: "2025-09-20T07:53:53Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T07:52:11Z"
    generateName: graphql-deploy-98cc44b8b-
    labels:
      app: graphql-app
      environment: prod
      pod-template-hash: 98cc44b8b
      project: zee-project
    name: graphql-deploy-98cc44b8b-zsw9g
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: graphql-deploy-98cc44b8b
      uid: 2c11f592-470c-4f4b-a86c-9e0cebabbc43
    resourceVersion: "121075588"
    uid: 2861d032-25c1-4b98-b9eb-901724012354
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: graphql-config
      - secretRef:
          name: graphql-secrets
      image: devzeelearn/graphql-prod:17
      imagePullPolicy: Always
      name: graphql-prod
      ports:
      - containerPort: 5015
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 250m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ss88n
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-ss88n
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:52:51Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:51:33Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-29T08:57:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-29T08:57:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:52:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e90605bcfc9454f4cfea4a68ab9a7cff5e4732a297a2effee568c67c382f1df1
      image: docker.io/devzeelearn/graphql-prod:17
      imageID: docker.io/devzeelearn/graphql-prod@sha256:fe29bef2726d6170eeffc8d76e87a0627a8811fe00b87be4965add5ff36b9431
      lastState:
        terminated:
          containerID: containerd://a04c09e06f242924d6df94cc1b8da7d453a2b2e25ce678238fbab4fc6da1937b
          exitCode: 137
          finishedAt: "2025-09-29T08:57:18Z"
          reason: OOMKilled
          startedAt: "2025-09-25T12:54:18Z"
      name: graphql-prod
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2025-09-29T08:57:21Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.191
    podIPs:
    - ip: 192.168.3.191
    qosClass: Burstable
    startTime: "2025-09-20T07:51:33Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-23T10:37:36Z"
    generateName: juapi-deploy-559fc8cf7c-
    labels:
      app: juapi-app
      environment: prod
      pod-template-hash: 559fc8cf7c
      project: zee-project
    name: juapi-deploy-559fc8cf7c-b7pql
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: juapi-deploy-559fc8cf7c
      uid: 57114159-ae4d-4210-a5aa-b881305455bf
    resourceVersion: "121590620"
    uid: 56cb80b4-9108-4c56-be6b-f1775fdd20e7
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: juapi-config
      - secretRef:
          name: juapi-secrets
      image: devzeelearn/juapi-prod:165
      imagePullPolicy: Always
      name: juapi
      ports:
      - containerPort: 5011
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 250m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-g89n9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-g89n9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-23T10:37:56Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-23T10:36:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-30T10:38:59Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-30T10:38:59Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-23T10:37:36Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://b1b0e8db59e7b8d975b70ac2f6f17504269a88faeabd2345d969057398b01ea5
      image: docker.io/devzeelearn/juapi-prod:165
      imageID: docker.io/devzeelearn/juapi-prod@sha256:6f687031c4149557f26fd469f132a59ed0c1553712501d94507c31e0e75e1d83
      lastState:
        terminated:
          containerID: containerd://842a831db4f97bf4f34f4997c39f9663070dbfe111be48c46fb1a5fd7516f763
          exitCode: 1
          finishedAt: "2025-09-30T10:38:56Z"
          reason: Error
          startedAt: "2025-09-23T10:37:56Z"
      name: juapi
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-09-30T10:38:59Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.211
    podIPs:
    - ip: 192.168.3.211
    qosClass: Burstable
    startTime: "2025-09-23T10:36:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T08:01:16Z"
    generateName: literanovacms-deploy-7cb9c56bc9-
    labels:
      app: literanovacms-app
      environment: prod
      pod-template-hash: 7cb9c56bc9
      project: zee-project
    name: literanovacms-deploy-7cb9c56bc9-4n8dg
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: literanovacms-deploy-7cb9c56bc9
      uid: 3c93fd9f-4809-4802-925a-eaa92f917939
    resourceVersion: "116660102"
    uid: ea2335a7-048b-4b1d-9aa2-fe4b75ae959f
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: literanovacms-config
      - secretRef:
          name: literanovacms-secrets
      image: devzeelearn/literanovacms-prod:8
      imagePullPolicy: Always
      name: literanovacms
      ports:
      - containerPort: 5011
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 256Mi
        requests:
          cpu: 500m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-sfjtj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-sfjtj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:02:20Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:02:18Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:02:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:02:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:02:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://de57b2cc91a76b535e1b5bef262a6593508dbb28599831c7a3cd08042ac8a715
      image: docker.io/devzeelearn/literanovacms-prod:8
      imageID: docker.io/devzeelearn/literanovacms-prod@sha256:51f324457951bb27369c7f020bf4540bacbe8a6ec3d6534d3806d4df3b17f57f
      lastState: {}
      name: literanovacms
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-20T08:02:20Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.203
    podIPs:
    - ip: 192.168.3.203
    qosClass: Burstable
    startTime: "2025-09-20T08:02:18Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T08:02:58Z"
    generateName: literanovacms-deploy-7cb9c56bc9-
    labels:
      app: literanovacms-app
      environment: prod
      pod-template-hash: 7cb9c56bc9
      project: zee-project
    name: literanovacms-deploy-7cb9c56bc9-f5s2g
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: literanovacms-deploy-7cb9c56bc9
      uid: 3c93fd9f-4809-4802-925a-eaa92f917939
    resourceVersion: "116660829"
    uid: 9497849c-6d5b-4e8e-8dfe-d7584cbbdc5b
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: literanovacms-config
      - secretRef:
          name: literanovacms-secrets
      image: devzeelearn/literanovacms-prod:8
      imagePullPolicy: Always
      name: literanovacms
      ports:
      - containerPort: 5011
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 256Mi
        requests:
          cpu: 500m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-t4825
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-t4825
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:04:00Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:03:57Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:04:00Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:04:00Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:04:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://2286ae22baba604ad7997efd67ea75c50a79ee267dd1e1eef042c83975ae15f0
      image: docker.io/devzeelearn/literanovacms-prod:8
      imageID: docker.io/devzeelearn/literanovacms-prod@sha256:51f324457951bb27369c7f020bf4540bacbe8a6ec3d6534d3806d4df3b17f57f
      lastState: {}
      name: literanovacms
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-20T08:03:59Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.206
    podIPs:
    - ip: 192.168.3.206
    qosClass: Burstable
    startTime: "2025-09-20T08:03:57Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T07:58:38Z"
    generateName: literanovacms-deploy-7cb9c56bc9-
    labels:
      app: literanovacms-app
      environment: prod
      pod-template-hash: 7cb9c56bc9
      project: zee-project
    name: literanovacms-deploy-7cb9c56bc9-xzgvn
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: literanovacms-deploy-7cb9c56bc9
      uid: 3c93fd9f-4809-4802-925a-eaa92f917939
    resourceVersion: "116659380"
    uid: 4caa879f-7032-4a8e-bde7-bef7687ebefa
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: literanovacms-config
      - secretRef:
          name: literanovacms-secrets
      image: devzeelearn/literanovacms-prod:8
      imagePullPolicy: Always
      name: literanovacms
      ports:
      - containerPort: 5011
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 256Mi
        requests:
          cpu: 500m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7q2lv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-7q2lv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:00:38Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:00:36Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:00:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:00:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:01:13Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://bef135b7ea9d792f58f1c2ae9c1bf6fea3b963a3bd810d69935015d3ed2959e3
      image: docker.io/devzeelearn/literanovacms-prod:8
      imageID: docker.io/devzeelearn/literanovacms-prod@sha256:51f324457951bb27369c7f020bf4540bacbe8a6ec3d6534d3806d4df3b17f57f
      lastState: {}
      name: literanovacms
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-20T08:00:38Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.202
    podIPs:
    - ip: 192.168.3.202
    qosClass: Burstable
    startTime: "2025-09-20T08:00:36Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T07:52:17Z"
    generateName: literaoctavecms-deploy-85c87cbb88-
    labels:
      app: literaoctavecms-app
      environment: prod
      pod-template-hash: 85c87cbb88
      project: zee-project
    name: literaoctavecms-deploy-85c87cbb88-8rmbj
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: literaoctavecms-deploy-85c87cbb88
      uid: c50cb490-7064-489a-8241-8485ad2be84b
    resourceVersion: "116655975"
    uid: 71370f31-f80b-421e-9d56-9f809dbd5dfe
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: literaoctavecms-config
      - secretRef:
          name: literaoctavecms-secrets
      image: devzeelearn/literaoctavecms-prod:6
      imagePullPolicy: Always
      name: literaoctavecms
      ports:
      - containerPort: 5011
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 4Gi
        requests:
          cpu: 500m
          memory: 2Gi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kpddh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-kpddh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:53:51Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:53:28Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:53:51Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:53:51Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://07fa5e837274473c2b27fd2bf6ccac0e07443e37fb1314e26916147b194149b4
      image: docker.io/devzeelearn/literaoctavecms-prod:6
      imageID: docker.io/devzeelearn/literaoctavecms-prod@sha256:cd499f946dac847422f711c7e86fe9546fdf8de8b33abb2910fe10c4be555644
      lastState: {}
      name: literaoctavecms
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-20T07:53:51Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.195
    podIPs:
    - ip: 192.168.3.195
    qosClass: Burstable
    startTime: "2025-09-20T07:53:28Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-23T10:38:03Z"
    generateName: lmsapi-deploy-7bdbb68dd9-
    labels:
      app: lmsapi-app
      environment: prod
      pod-template-hash: 7bdbb68dd9
      project: zee-project
    name: lmsapi-deploy-7bdbb68dd9-tr2x9
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: lmsapi-deploy-7bdbb68dd9
      uid: 9e2c1c0e-58cf-4bb7-8bae-822d1d314edd
    resourceVersion: "118198706"
    uid: 4e72073c-e5d9-4c4a-b0b8-a00b7d876763
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: lmsapi-config
      - secretRef:
          name: lmsapi-secrets
      image: devzeelearn/lmsapi-prod:221
      imagePullPolicy: IfNotPresent
      name: lmsapi
      ports:
      - containerPort: 5011
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 250m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8d7sc
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-8d7sc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-23T10:38:13Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-23T10:37:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-23T10:38:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-23T10:38:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-23T10:38:03Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://51b1d484a4dbde1b01069a9b20031ac590505a7afbb2934efaaade41fa3c67a5
      image: docker.io/devzeelearn/lmsapi-prod:221
      imageID: docker.io/devzeelearn/lmsapi-prod@sha256:77cb851dd0e9337d8c0db612d103e9d66f0dc52d867009e715111e7182f14664
      lastState: {}
      name: lmsapi
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-23T10:38:13Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.212
    podIPs:
    - ip: 192.168.3.212
    qosClass: Burstable
    startTime: "2025-09-23T10:37:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T07:55:00Z"
    generateName: novachat-deploy-6c57d7bf4b-
    labels:
      app: novachat-app
      environment: prod
      pod-template-hash: 6c57d7bf4b
      project: zee-project
    name: novachat-deploy-6c57d7bf4b-cfqgm
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: novachat-deploy-6c57d7bf4b
      uid: 3cc92b9d-a42a-4ada-8d86-5cd652dc7988
    resourceVersion: "116656526"
    uid: c53d85b1-3d86-48b7-b3b9-dcceddc17060
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: novachat-config
      - secretRef:
          name: novachat-secrets
      image: devzeelearn/novachat-prod:8
      imagePullPolicy: Always
      name: novachat
      ports:
      - containerPort: 4011
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 2Gi
        requests:
          cpu: 250m
          memory: 1Gi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-brkz5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-brkz5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:25Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:55:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://8d69772b3d6a2a303d865c930e0c2bab1d0da2082ef4ea6b50b624d39d351d4c
      image: docker.io/devzeelearn/novachat-prod:8
      imageID: docker.io/devzeelearn/novachat-prod@sha256:b8fa7b83c7dfb9580d22ec04dcd2d064276fa16122d366f752b413a2d8660450
      lastState: {}
      name: novachat
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-20T07:54:24Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.198
    podIPs:
    - ip: 192.168.3.198
    qosClass: Burstable
    startTime: "2025-09-20T07:54:22Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T07:54:49Z"
    generateName: pentemind-24-deploy-6f7d54db84-
    labels:
      app: pentemind-apps
      environment: prod
      pod-template-hash: 6f7d54db84
      project: zee-project
    name: pentemind-24-deploy-6f7d54db84-sfd8b
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: pentemind-24-deploy-6f7d54db84
      uid: d42c0e18-806c-4bfb-aae2-6e04afa5abd1
    resourceVersion: "116656547"
    uid: d9bba070-8bb0-4de4-a4bd-88faafdee474
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: pentemind-config-24
      - secretRef:
          name: pentemind-secrets-24
      image: devzeelearn/pentemind-apiv1-2024-prod:35
      imagePullPolicy: Always
      name: pentemind
      ports:
      - containerPort: 5005
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 250m
          memory: 256Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bxtth
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-bxtth
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:27Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:27Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:27Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:55:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://67b40580f48e06a9ff3e43815f6c34600ee2e482f2b05fc925199ff96e4536a1
      image: docker.io/devzeelearn/pentemind-apiv1-2024-prod:35
      imageID: docker.io/devzeelearn/pentemind-apiv1-2024-prod@sha256:383f2277564074f70786a5c853b0fa0366c39e03e000f1addee163e68c403d46
      lastState: {}
      name: pentemind
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-20T07:54:26Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.199
    podIPs:
    - ip: 192.168.3.199
    qosClass: Burstable
    startTime: "2025-09-20T07:54:22Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T07:52:12Z"
    generateName: pentemind-24-deploy-6f7d54db84-
    labels:
      app: pentemind-apps
      environment: prod
      pod-template-hash: 6f7d54db84
      project: zee-project
    name: pentemind-24-deploy-6f7d54db84-vwkwx
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: pentemind-24-deploy-6f7d54db84
      uid: d42c0e18-806c-4bfb-aae2-6e04afa5abd1
    resourceVersion: "116656348"
    uid: b4eaec1a-e5b9-46ab-9eec-2284df1a87ec
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: pentemind-config-24
      - secretRef:
          name: pentemind-secrets-24
      image: devzeelearn/pentemind-apiv1-2024-prod:35
      imagePullPolicy: Always
      name: pentemind
      ports:
      - containerPort: 5005
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 250m
          memory: 256Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-p72wk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-p72wk
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:11Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:07Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:11Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:11Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T07:54:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://8dcfd4f7b218aac33552f38e92e8588cd6dda2a0674c99fd9bc066bcd94aef1d
      image: docker.io/devzeelearn/pentemind-apiv1-2024-prod:35
      imageID: docker.io/devzeelearn/pentemind-apiv1-2024-prod@sha256:383f2277564074f70786a5c853b0fa0366c39e03e000f1addee163e68c403d46
      lastState: {}
      name: pentemind
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-20T07:54:10Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.197
    podIPs:
    - ip: 192.168.3.197
    qosClass: Burstable
    startTime: "2025-09-20T07:54:07Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-20T08:01:48Z"
    generateName: pentemind-25-deploy-66ffd97754-
    labels:
      app: pentemind-app
      environment: prod
      pod-template-hash: 66ffd97754
      project: zee-project
    name: pentemind-25-deploy-66ffd97754-dxbjb
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: pentemind-25-deploy-66ffd97754
      uid: 6ae05a0f-7d00-43b5-8e7a-907cb16e49e4
    resourceVersion: "116660343"
    uid: 9bdccbf9-73f4-498b-851b-10d6a080fb23
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: pentemind-config-25
      - secretRef:
          name: pentemind-secrets-25
      image: devzeelearn/pentemind-apiv1-2025-prod:18
      imagePullPolicy: Always
      name: pentemind
      ports:
      - containerPort: 5005
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 512Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pp4b9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-pp4b9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:02:53Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:02:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:02:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:02:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-20T08:03:28Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://3b0ea65b3b43ad6afa3a6de401f7c251e750172af648325661a0ec972f19b5c5
      image: docker.io/devzeelearn/pentemind-apiv1-2025-prod:18
      imageID: docker.io/devzeelearn/pentemind-apiv1-2025-prod@sha256:8d4aeb4ac277e4a98ad15193d076e768c2edfceb698e8eaf197a5cf73f90c458
      lastState: {}
      name: pentemind
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-20T08:02:53Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.204
    podIPs:
    - ip: 192.168.3.204
    qosClass: Burstable
    startTime: "2025-09-20T08:02:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-09-20T13:21:22+05:30"
    creationTimestamp: "2025-09-25T06:18:14Z"
    generateName: zllsaathiapi-deploy-7fb44565c9-
    labels:
      app: zllsaathiapi-app
      environment: prod
      pod-template-hash: 7fb44565c9
      project: zee-project
    name: zllsaathiapi-deploy-7fb44565c9-pfh7j
    namespace: prod
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: zllsaathiapi-deploy-7fb44565c9
      uid: 0a5cef09-749c-4517-bc06-2549a1313c09
    resourceVersion: "119091998"
    uid: 183a8905-b14d-49bf-945d-3849b15d3b3b
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: zllsaathiapi-config
      - secretRef:
          name: zllsaathiapi-secrets
      image: devzeelearn/zllsaathiapi-prod:8
      imagePullPolicy: Always
      name: zllsaathiapi
      ports:
      - containerPort: 3000
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 256Mi
        requests:
          cpu: 500m
          memory: 128Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-nfrnx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: zee-docker-secret
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-nfrnx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-09-25T06:17:43Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-09-25T06:17:32Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-09-25T06:17:43Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-09-25T06:17:43Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-09-25T06:18:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://b5a642490a0f4ae23519e90b3e73fd63d43408e5f534882722cb1833b1c95859
      image: docker.io/devzeelearn/zllsaathiapi-prod:8
      imageID: docker.io/devzeelearn/zllsaathiapi-prod@sha256:828a3341c2c090683a0568af3961644b5dadcacbac4980546ecc62162f472e8a
      lastState: {}
      name: zllsaathiapi
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-09-25T06:17:42Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.213
    podIPs:
    - ip: 192.168.3.213
    qosClass: Burstable
    startTime: "2025-09-25T06:17:32Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-06-20T20:42:57Z"
    generateName: rabbitmq-cluster-server-
    labels:
      app.kubernetes.io/component: rabbitmq
      app.kubernetes.io/name: rabbitmq-cluster
      app.kubernetes.io/part-of: rabbitmq
      apps.kubernetes.io/pod-index: "1"
      controller-revision-hash: rabbitmq-cluster-server-cc559864f
      statefulset.kubernetes.io/pod-name: rabbitmq-cluster-server-1
    name: rabbitmq-cluster-server-1
    namespace: rbmq
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: rabbitmq-cluster-server
      uid: 3c5ea3c8-a946-4043-8866-28d13d2d3385
    resourceVersion: "70962008"
    uid: d060f233-12a9-40ac-a86a-9d970b299ae1
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: K8S_SERVICE_NAME
        value: rabbitmq-cluster-nodes
      - name: RABBITMQ_ENABLED_PLUGINS_FILE
        value: /operator/enabled_plugins
      - name: RABBITMQ_USE_LONGNAME
        value: "true"
      - name: RABBITMQ_NODENAME
        value: rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE)
      - name: K8S_HOSTNAME_SUFFIX
        value: .$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE)
      image: docker.io/bitnami/rabbitmq:4.0.6-debian-12-r0
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - if [ ! -z "$(cat /etc/pod-info/skipPreStopChecks)" ]; then exit 0; fi;
              rabbitmq-upgrade await_online_quorum_plus_one -t 604800 && rabbitmq-upgrade
              await_online_synchronized_mirror -t 604800 || true && rabbitmq-upgrade
              drain -t 604800
      name: rabbitmq
      ports:
      - containerPort: 4369
        name: epmd
        protocol: TCP
      - containerPort: 5672
        name: amqp
        protocol: TCP
      - containerPort: 15672
        name: management
        protocol: TCP
      - containerPort: 15692
        name: prometheus
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: amqp
        timeoutSeconds: 5
      resources:
        limits:
          cpu: "2"
          memory: 2Gi
        requests:
          cpu: "1"
          memory: 2Gi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/rabbitmq/
        name: rabbitmq-erlang-cookie
      - mountPath: /var/lib/rabbitmq/mnesia/
        name: persistence
      - mountPath: /operator
        name: rabbitmq-plugins
      - mountPath: /etc/rabbitmq/conf.d/10-operatorDefaults.conf
        name: rabbitmq-confd
        subPath: operatorDefaults.conf
      - mountPath: /etc/rabbitmq/conf.d/90-userDefinedConfiguration.conf
        name: rabbitmq-confd
        subPath: userDefinedConfiguration.conf
      - mountPath: /etc/pod-info/
        name: pod-info
      - mountPath: /etc/rabbitmq/conf.d/11-default_user.conf
        name: rabbitmq-confd
        subPath: default_user.conf
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xvfwj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: rabbitmq-cluster-server-1
    initContainers:
    - command:
      - sh
      - -c
      - cp /tmp/erlang-cookie-secret/.erlang.cookie /var/lib/rabbitmq/.erlang.cookie
        && chmod 600 /var/lib/rabbitmq/.erlang.cookie ; cp /tmp/rabbitmq-plugins/enabled_plugins
        /operator/enabled_plugins ; echo '[default]' > /var/lib/rabbitmq/.rabbitmqadmin.conf
        && sed -e 's/default_user/username/' -e 's/default_pass/password/' /tmp/default_user.conf
        >> /var/lib/rabbitmq/.rabbitmqadmin.conf && chmod 600 /var/lib/rabbitmq/.rabbitmqadmin.conf
        ; sleep 30
      image: docker.io/bitnami/rabbitmq:4.0.6-debian-12-r0
      imagePullPolicy: IfNotPresent
      name: setup-container
      resources:
        limits:
          cpu: 100m
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 500Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/rabbitmq-plugins/
        name: plugins-conf
      - mountPath: /var/lib/rabbitmq/
        name: rabbitmq-erlang-cookie
      - mountPath: /tmp/erlang-cookie-secret/
        name: erlang-cookie-secret
      - mountPath: /operator
        name: rabbitmq-plugins
      - mountPath: /var/lib/rabbitmq/mnesia/
        name: persistence
      - mountPath: /tmp/default_user.conf
        name: rabbitmq-confd
        subPath: default_user.conf
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xvfwj
        readOnly: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 0
      runAsUser: 999
    serviceAccount: rabbitmq-cluster-server
    serviceAccountName: rabbitmq-cluster-server
    subdomain: rabbitmq-cluster-nodes
    terminationGracePeriodSeconds: 604800
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    topologySpreadConstraints:
    - labelSelector:
        matchLabels:
          app.kubernetes.io/name: rabbitmq-cluster
      maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
    volumes:
    - name: persistence
      persistentVolumeClaim:
        claimName: persistence-rabbitmq-cluster-server-1
    - configMap:
        defaultMode: 420
        name: rabbitmq-cluster-plugins-conf
      name: plugins-conf
    - name: rabbitmq-confd
      projected:
        defaultMode: 420
        sources:
        - configMap:
            items:
            - key: operatorDefaults.conf
              path: operatorDefaults.conf
            - key: userDefinedConfiguration.conf
              path: userDefinedConfiguration.conf
            name: rabbitmq-cluster-server-conf
        - secret:
            items:
            - key: default_user.conf
              path: default_user.conf
            name: rabbitmq-cluster-default-user
    - emptyDir: {}
      name: rabbitmq-erlang-cookie
    - name: erlang-cookie-secret
      secret:
        defaultMode: 420
        secretName: rabbitmq-cluster-erlang-cookie
    - emptyDir: {}
      name: rabbitmq-plugins
    - downwardAPI:
        defaultMode: 420
        items:
        - fieldRef:
            apiVersion: v1
            fieldPath: metadata.labels['skipPreStopChecks']
          path: skipPreStopChecks
      name: pod-info
    - name: kube-api-access-xvfwj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:21Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:52Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:44:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:44:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:42:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://17362af6f3db09524aab28cdbf3826985034a0cff5b98665238ec5448bf16389
      image: docker.io/bitnami/rabbitmq:4.0.6-debian-12-r0
      imageID: docker.io/bitnami/rabbitmq@sha256:46d28071536bdaf2e8469e51502f101e893fd5458da36100ce85e9e0320a0dff
      lastState: {}
      name: rabbitmq
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:43:52Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    initContainerStatuses:
    - containerID: containerd://5a569061c86cd7752e0d2c80f6cd348ca5770adb3c974fc6f8a28d46f078fb39
      image: docker.io/bitnami/rabbitmq:4.0.6-debian-12-r0
      imageID: docker.io/bitnami/rabbitmq@sha256:46d28071536bdaf2e8469e51502f101e893fd5458da36100ce85e9e0320a0dff
      lastState: {}
      name: setup-container
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://5a569061c86cd7752e0d2c80f6cd348ca5770adb3c974fc6f8a28d46f078fb39
          exitCode: 0
          finishedAt: "2025-06-20T20:43:51Z"
          reason: Completed
          startedAt: "2025-06-20T20:43:21Z"
    phase: Running
    podIP: 192.168.3.241
    podIPs:
    - ip: 192.168.3.241
    qosClass: Burstable
    startTime: "2025-06-20T20:43:17Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-06-20T20:42:57Z"
    generateName: rabbitmq-cluster-server-
    labels:
      app.kubernetes.io/component: rabbitmq
      app.kubernetes.io/name: rabbitmq-cluster
      app.kubernetes.io/part-of: rabbitmq
      apps.kubernetes.io/pod-index: "2"
      controller-revision-hash: rabbitmq-cluster-server-cc559864f
      statefulset.kubernetes.io/pod-name: rabbitmq-cluster-server-2
    name: rabbitmq-cluster-server-2
    namespace: rbmq
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: rabbitmq-cluster-server
      uid: 3c5ea3c8-a946-4043-8866-28d13d2d3385
    resourceVersion: "70962003"
    uid: 1d1bdc41-9dd0-4b3e-abe1-72877d97506d
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: MY_POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: K8S_SERVICE_NAME
        value: rabbitmq-cluster-nodes
      - name: RABBITMQ_ENABLED_PLUGINS_FILE
        value: /operator/enabled_plugins
      - name: RABBITMQ_USE_LONGNAME
        value: "true"
      - name: RABBITMQ_NODENAME
        value: rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE)
      - name: K8S_HOSTNAME_SUFFIX
        value: .$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE)
      image: docker.io/bitnami/rabbitmq:4.0.6-debian-12-r0
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - if [ ! -z "$(cat /etc/pod-info/skipPreStopChecks)" ]; then exit 0; fi;
              rabbitmq-upgrade await_online_quorum_plus_one -t 604800 && rabbitmq-upgrade
              await_online_synchronized_mirror -t 604800 || true && rabbitmq-upgrade
              drain -t 604800
      name: rabbitmq
      ports:
      - containerPort: 4369
        name: epmd
        protocol: TCP
      - containerPort: 5672
        name: amqp
        protocol: TCP
      - containerPort: 15672
        name: management
        protocol: TCP
      - containerPort: 15692
        name: prometheus
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: amqp
        timeoutSeconds: 5
      resources:
        limits:
          cpu: "2"
          memory: 2Gi
        requests:
          cpu: "1"
          memory: 2Gi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/rabbitmq/
        name: rabbitmq-erlang-cookie
      - mountPath: /var/lib/rabbitmq/mnesia/
        name: persistence
      - mountPath: /operator
        name: rabbitmq-plugins
      - mountPath: /etc/rabbitmq/conf.d/10-operatorDefaults.conf
        name: rabbitmq-confd
        subPath: operatorDefaults.conf
      - mountPath: /etc/rabbitmq/conf.d/90-userDefinedConfiguration.conf
        name: rabbitmq-confd
        subPath: userDefinedConfiguration.conf
      - mountPath: /etc/pod-info/
        name: pod-info
      - mountPath: /etc/rabbitmq/conf.d/11-default_user.conf
        name: rabbitmq-confd
        subPath: default_user.conf
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6g8jf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: rabbitmq-cluster-server-2
    initContainers:
    - command:
      - sh
      - -c
      - cp /tmp/erlang-cookie-secret/.erlang.cookie /var/lib/rabbitmq/.erlang.cookie
        && chmod 600 /var/lib/rabbitmq/.erlang.cookie ; cp /tmp/rabbitmq-plugins/enabled_plugins
        /operator/enabled_plugins ; echo '[default]' > /var/lib/rabbitmq/.rabbitmqadmin.conf
        && sed -e 's/default_user/username/' -e 's/default_pass/password/' /tmp/default_user.conf
        >> /var/lib/rabbitmq/.rabbitmqadmin.conf && chmod 600 /var/lib/rabbitmq/.rabbitmqadmin.conf
        ; sleep 30
      image: docker.io/bitnami/rabbitmq:4.0.6-debian-12-r0
      imagePullPolicy: IfNotPresent
      name: setup-container
      resources:
        limits:
          cpu: 100m
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 500Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/rabbitmq-plugins/
        name: plugins-conf
      - mountPath: /var/lib/rabbitmq/
        name: rabbitmq-erlang-cookie
      - mountPath: /tmp/erlang-cookie-secret/
        name: erlang-cookie-secret
      - mountPath: /operator
        name: rabbitmq-plugins
      - mountPath: /var/lib/rabbitmq/mnesia/
        name: persistence
      - mountPath: /tmp/default_user.conf
        name: rabbitmq-confd
        subPath: default_user.conf
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6g8jf
        readOnly: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 0
      runAsUser: 999
    serviceAccount: rabbitmq-cluster-server
    serviceAccountName: rabbitmq-cluster-server
    subdomain: rabbitmq-cluster-nodes
    terminationGracePeriodSeconds: 604800
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    topologySpreadConstraints:
    - labelSelector:
        matchLabels:
          app.kubernetes.io/name: rabbitmq-cluster
      maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
    volumes:
    - name: persistence
      persistentVolumeClaim:
        claimName: persistence-rabbitmq-cluster-server-2
    - configMap:
        defaultMode: 420
        name: rabbitmq-cluster-plugins-conf
      name: plugins-conf
    - name: rabbitmq-confd
      projected:
        defaultMode: 420
        sources:
        - configMap:
            items:
            - key: operatorDefaults.conf
              path: operatorDefaults.conf
            - key: userDefinedConfiguration.conf
              path: userDefinedConfiguration.conf
            name: rabbitmq-cluster-server-conf
        - secret:
            items:
            - key: default_user.conf
              path: default_user.conf
            name: rabbitmq-cluster-default-user
    - emptyDir: {}
      name: rabbitmq-erlang-cookie
    - name: erlang-cookie-secret
      secret:
        defaultMode: 420
        secretName: rabbitmq-cluster-erlang-cookie
    - emptyDir: {}
      name: rabbitmq-plugins
    - downwardAPI:
        defaultMode: 420
        items:
        - fieldRef:
            apiVersion: v1
            fieldPath: metadata.labels['skipPreStopChecks']
          path: skipPreStopChecks
      name: pod-info
    - name: kube-api-access-6g8jf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:21Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:43:52Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:44:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:44:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:42:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://bc02b34f999e6666aa5e8ad73922d47ac4d55f32a0a8b112949705c615c099ee
      image: docker.io/bitnami/rabbitmq:4.0.6-debian-12-r0
      imageID: docker.io/bitnami/rabbitmq@sha256:46d28071536bdaf2e8469e51502f101e893fd5458da36100ce85e9e0320a0dff
      lastState: {}
      name: rabbitmq
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:43:52Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    initContainerStatuses:
    - containerID: containerd://c8d7f776ec4813502be845aad961a81de598680e0e87b1d0ce1fe7e543866676
      image: docker.io/bitnami/rabbitmq:4.0.6-debian-12-r0
      imageID: docker.io/bitnami/rabbitmq@sha256:46d28071536bdaf2e8469e51502f101e893fd5458da36100ce85e9e0320a0dff
      lastState: {}
      name: setup-container
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://c8d7f776ec4813502be845aad961a81de598680e0e87b1d0ce1fe7e543866676
          exitCode: 0
          finishedAt: "2025-06-20T20:43:51Z"
          reason: Completed
          startedAt: "2025-06-20T20:43:21Z"
    phase: Running
    podIP: 192.168.3.240
    podIPs:
    - ip: 192.168.3.240
    qosClass: Burstable
    startTime: "2025-06-20T20:43:17Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-04-16T11:38:08Z"
    generateName: redis-594bb96598-
    labels:
      app: redis
      pod-template-hash: 594bb96598
    name: redis-594bb96598-5zds9
    namespace: redis
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: redis-594bb96598
      uid: 8a852391-6299-4ce4-b063-b4c662ad3a7f
    resourceVersion: "70961422"
    uid: ee730310-1a7a-45bf-96d9-7f30ef466d78
  spec:
    containers:
    - command:
      - redis-server
      - --requirepass
      - $(REDIS_PASSWORD)
      env:
      - name: REDIS_PASSWORD
        value: ogJ4MKWbh0
      image: redis:latest
      imagePullPolicy: Always
      name: redis
      ports:
      - containerPort: 6379
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-z84s9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: zee8608workerapi02
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-z84s9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:37Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:45:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:37Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-06-20T20:32:37Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-04-16T12:48:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ba93434e92ed28034c5b72d4c1278427131efba6bf2b29cb32a1bae57b4212b7
      image: docker.io/library/redis:latest
      imageID: docker.io/library/redis@sha256:1b835e5a8d5db58e8b718850bf43a68ef5a576fc68301fd08a789b20b4eecb61
      lastState:
        terminated:
          containerID: containerd://072a99a7b47dbd4b97f82d7df4174becd8d0c20c42f1dcb968f383dab79e86f8
          exitCode: 255
          finishedAt: "2025-06-20T20:30:30Z"
          reason: Unknown
          startedAt: "2025-04-16T12:46:31Z"
      name: redis
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-06-20T20:32:36Z"
    hostIP: 10.48.219.139
    hostIPs:
    - ip: 10.48.219.139
    phase: Running
    podIP: 192.168.3.229
    podIPs:
    - ip: 192.168.3.229
    qosClass: BestEffort
    startTime: "2025-04-16T12:45:55Z"
kind: List
metadata:
  resourceVersion: ""
